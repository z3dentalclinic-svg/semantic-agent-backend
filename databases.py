"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ –∏ –±—Ä–µ–Ω–¥–æ–≤.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è:
- –ó–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ geonamescache
- –ó–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –±—Ä–µ–Ω–¥–æ–≤ —Ç–µ—Ö–Ω–∏–∫–∏
- –ü–æ–∏—Å–∫–∞ –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏
"""

import geonamescache
import pymorphy3
from typing import Set, Optional, List, Dict


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
morph = pymorphy3.MorphAnalyzer()


def load_geonames_db(country_code: Optional[str] = None) -> Set[str]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ geonamescache.
    
    Args:
        country_code: –ö–æ–¥ —Å—Ç—Ä–∞–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'UA' –¥–ª—è –£–∫—Ä–∞–∏–Ω—ã, 'RU' –¥–ª—è –†–æ—Å—Å–∏–∏).
                     –ï—Å–ª–∏ None, –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –≤—Å–µ –≥–æ—Ä–æ–¥–∞ –º–∏—Ä–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è).
    
    Returns:
        –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –Ω–∞–∑–≤–∞–Ω–∏–π –≥–æ—Ä–æ–¥–æ–≤ + —Å—Ç—Ä–∞–Ω –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    """
    gc = geonamescache.GeonamesCache()
    cities = gc.get_cities()
    
    city_names = set()
    
    for city_data in cities.values():
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Å—Ç—Ä–∞–Ω–µ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞
        if country_code and city_data.get('countrycode') != country_code:
            continue
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞
        name = city_data.get('name', '').lower()
        if name:
            city_names.add(name)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
        alt_names = city_data.get('alternatenames', [])
        for alt_name in alt_names:
            if alt_name:
                city_names.add(alt_name.lower())
    
    # === –°–¢–†–ê–ù–´ (geonamescache —Ö—Ä–∞–Ω–∏—Ç —Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è) ===
    countries = gc.get_countries()
    for country_data in countries.values():
        name = country_data.get('name', '').lower()
        if name:
            city_names.add(name)
    
    # –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç—Ä–∞–Ω (geonamescache –∏—Ö –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç)
    # –≠—Ç–æ –ù–ï —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ ‚Äî —ç—Ç–æ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è –ë–î, –∫–∞–∫ –∏ –≥–æ—Ä–æ–¥–∞
    russian_countries = {
        '—É–∫—Ä–∞–∏–Ω–∞', '—Ä–æ—Å—Å–∏—è', '–±–µ–ª–∞—Ä—É—Å—å', '–±–µ–ª–æ—Ä—É—Å—Å–∏—è', '–∫–∞–∑–∞—Ö—Å—Ç–∞–Ω',
        '–ø–æ–ª—å—à–∞', '–≥–µ—Ä–º–∞–Ω–∏—è', '—Ñ—Ä–∞–Ω—Ü–∏—è', '–∏—Ç–∞–ª–∏—è', '–∏—Å–ø–∞–Ω–∏—è',
        '–∞–Ω–≥–ª–∏—è', '–≤–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏—è', '—Å—à–∞', '–∞–º–µ—Ä–∏–∫–∞',
        '—Ç—É—Ä—Ü–∏—è', '–µ–≥–∏–ø–µ—Ç', '–≥—Ä–µ—Ü–∏—è', '—á–µ—Ö–∏—è', '–∞–≤—Å—Ç—Ä–∏—è',
        '—à–≤–µ—Ü–∏—è', '–Ω–æ—Ä–≤–µ–≥–∏—è', '—Ñ–∏–Ω–ª—è–Ω–¥–∏—è', '–¥–∞–Ω–∏—è',
        '–Ω–∏–¥–µ—Ä–ª–∞–Ω–¥—ã', '–≥–æ–ª–ª–∞–Ω–¥–∏—è', '–±–µ–ª—å–≥–∏—è', '—à–≤–µ–π—Ü–∞—Ä–∏—è',
        '–ø–æ—Ä—Ç—É–≥–∞–ª–∏—è', '—Ä—É–º—ã–Ω–∏—è', '–±–æ–ª–≥–∞—Ä–∏—è', '—Å–µ—Ä–±–∏—è', '—Ö–æ—Ä–≤–∞—Ç–∏—è',
        '—Å–ª–æ–≤–∞–∫–∏—è', '—Å–ª–æ–≤–µ–Ω–∏—è', '–≤–µ–Ω–≥—Ä–∏—è', '–º–æ–ª–¥–æ–≤–∞', '–º–æ–ª–¥–∞–≤–∏—è',
        '–ª–∏—Ç–≤–∞', '–ª–∞—Ç–≤–∏—è', '—ç—Å—Ç–æ–Ω–∏—è', '–≥—Ä—É–∑–∏—è', '–∞—Ä–º–µ–Ω–∏—è', '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω',
        '—É–∑–±–µ–∫–∏—Å—Ç–∞–Ω', '—Ç–∞–¥–∂–∏–∫–∏—Å—Ç–∞–Ω', '–∫—ã—Ä–≥—ã–∑—Å—Ç–∞–Ω', '—Ç—É—Ä–∫–º–µ–Ω–∏—Å—Ç–∞–Ω',
        '–∫–∏—Ç–∞–π', '—è–ø–æ–Ω–∏—è', '–∫–æ—Ä–µ—è', '–∏–Ω–¥–∏—è', '—Ç–∞–∏–ª–∞–Ω–¥', '–≤—å–µ—Ç–Ω–∞–º',
        '–∏–Ω–¥–æ–Ω–µ–∑–∏—è', '–º–∞–ª–∞–π–∑–∏—è', '—Å–∏–Ω–≥–∞–ø—É—Ä', '—Ñ–∏–ª–∏–ø–ø–∏–Ω—ã',
        '–∞–≤—Å—Ç—Ä–∞–ª–∏—è', '–∫–∞–Ω–∞–¥–∞', '–º–µ–∫—Å–∏–∫–∞', '–±—Ä–∞–∑–∏–ª–∏—è', '–∞—Ä–≥–µ–Ω—Ç–∏–Ω–∞',
        '–∏–∑—Ä–∞–∏–ª—å', '–æ–∞—ç', '—ç–º–∏—Ä–∞—Ç—ã', '—Å–∞—É–¥–æ–≤—Å–∫–∞—è –∞—Ä–∞–≤–∏—è',
    }
    city_names.update(russian_countries)
    
    return city_names


def load_brands_db() -> Set[str]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –±—Ä–µ–Ω–¥–æ–≤.
    
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
    1. brands.json (–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è fetch_brands.py –∏–∑ Wikidata)
    2. –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π fallback (~100 –±—Ä–µ–Ω–¥–æ–≤)
    
    Returns:
        –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –Ω–∞–∑–≤–∞–Ω–∏–π –±—Ä–µ–Ω–¥–æ–≤ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    """
    import os
    import json
    
    # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å brands.json
    for path in [
        os.path.join(os.path.dirname(__file__), 'brands.json'),
        os.path.join(os.path.dirname(os.path.abspath(__file__)), 'brands.json'),
        'brands.json',
    ]:
        if os.path.exists(path):
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                brands = set(data.get("brands", []))
                print(f"‚úÖ brands.json loaded: {len(brands)} brands from {path}")
                return brands
            except Exception as e:
                print(f"‚ö†Ô∏è Error loading brands.json: {e}")
    
    # Fallback: –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä
    print("‚ö†Ô∏è brands.json not found, using built-in fallback (limited)")
    brands = {
        'samsung', '—Å–∞–º—Å—É–Ω–≥', 'lg', '–ª–∂', '—ç–ª–¥–∂–∏',
        'dyson', '–¥–∞–π—Å–æ–Ω', 'xiaomi', '—Å—è–æ–º–∏',
        'philips', '—Ñ–∏–ª–∏–ø—Å', 'bosch', '–±–æ—à',
        'electrolux', '—ç–ª–µ–∫—Ç—Ä–æ–ª—é–∫—Å', 'thomas', '—Ç–æ–º–∞—Å',
        'karcher', '–∫–µ—Ä—Ö–µ—Ä', 'miele', '–º–∏–ª–µ',
        'apple', '—ç–ø–ª', 'sony', '—Å–æ–Ω–∏',
        'panasonic', '–ø–∞–Ω–∞—Å–æ–Ω–∏–∫', 'hitachi', '—Ö–∏—Ç–∞—á–∏',
        'toyota', '—Ç–æ–π–æ—Ç–∞', 'bmw', '–±–º–≤',
        'mercedes', '–º–µ—Ä—Å–µ–¥–µ—Å', 'honda', '—Ö–æ–Ω–¥–∞',
        'nike', '–Ω–∞–π–∫', 'adidas', '–∞–¥–∏–¥–∞—Å',
        'ikea', '–∏–∫–µ–∞', 'bork', '–±–æ—Ä–∫',
        '–∞—Ç–ª–∞–Ω—Ç', '–≥–æ—Ä–µ–Ω—å–µ', 'redmond', '—Ä–µ–¥–º–æ–Ω–¥',
    }
    return brands


def get_lemma(word: str) -> str:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ª–µ–º–º—É (–Ω–∞—á–∞–ª—å–Ω—É—é —Ñ–æ—Ä–º—É) —Å–ª–æ–≤–∞.
    
    Args:
        word: –ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ
    
    Returns:
        –õ–µ–º–º–∞ —Å–ª–æ–≤–∞ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    
    Examples:
        >>> get_lemma('–∫–∏—î–≤—ñ')
        '–∫–∏—ó–≤'
        >>> get_lemma('–∫–∏–µ–≤—É')
        '–∫–∏–µ–≤'
    """
    parsed = morph.parse(word.lower())[0]
    return parsed.normal_form


def normalize_for_search(text: str) -> List[str]:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞: —Ä–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ —Å–ª–æ–≤–∞ –∏ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç.
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
    
    Returns:
        –°–ø–∏—Å–æ–∫ –ª–µ–º–º –≤—Å–µ—Ö —Å–ª–æ–≤
    
    Examples:
        >>> normalize_for_search('—Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤')
        ['—Ä–µ–º–æ–Ω—Ç', '–ø—ã–ª–µ—Å–æ—Å']
    """
    words = text.lower().split()
    lemmas = [get_lemma(word) for word in words]
    return lemmas


def search_in_db(text: str, database: Set[str], use_lemma: bool = True) -> bool:
    """
    –ò—â–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
        database: –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö (–º–Ω–æ–∂–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫)
        use_lemma: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é
    
    Returns:
        True –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –∏–Ω–∞—á–µ False
    
    Examples:
        >>> brands = {'samsung', 'lg'}
        >>> search_in_db('samsung', brands)
        True
        >>> search_in_db('—Å–∞–º—Å—É–Ω–≥', brands)
        False
        >>> search_in_db('unknown', brands)
        False
    """
    text_lower = text.lower().strip()
    
    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if text_lower in database:
        return True
    
    # –ü–æ–∏—Å–∫ –ø–æ –ª–µ–º–º–∞–º –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
    if use_lemma:
        words = text_lower.split()
        for word in words:
            lemma = get_lemma(word)
            if lemma in database:
                return True
    
    return False


def find_cities_in_text(text: str, cities_db: Set[str]) -> List[str]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –≥–æ—Ä–æ–¥–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ.
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        cities_db: –ë–∞–∑–∞ –≥–æ—Ä–æ–¥–æ–≤
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤
    
    Examples:
        >>> cities = {'–∫–∏–µ–≤', '–æ–¥–µ—Å—Å–∞', '–ª—å–≤–æ–≤'}
        >>> find_cities_in_text('–∫–∏–µ–≤ –æ–¥–µ—Å—Å–∞', cities)
        ['–∫–∏–µ–≤', '–æ–¥–µ—Å—Å–∞']
    """
    found = []
    words = text.lower().split()
    
    for word in words:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if word in cities_db:
            found.append(word)
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–µ–º–º—É
        lemma = get_lemma(word)
        if lemma in cities_db:
            found.append(lemma)
    
    return found


def find_brands_in_text(text: str, brands_db: Set[str]) -> List[str]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±—Ä–µ–Ω–¥–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ.
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        brands_db: –ë–∞–∑–∞ –±—Ä–µ–Ω–¥–æ–≤
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤
    
    Examples:
        >>> brands = {'samsung', 'lg', 'dyson'}
        >>> find_brands_in_text('samsung lg', brands)
        ['samsung', 'lg']
    """
    found = []
    words = text.lower().split()
    
    for word in words:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if word in brands_db:
            found.append(word)
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–µ–º–º—É
        lemma = get_lemma(word)
        if lemma in brands_db:
            found.append(lemma)
    
    return found


# ==================== –¢–ï–°–¢–´ ====================

def run_tests():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–∞—Ö."""
    
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–£–õ–Ø –ë–ê–ó –î–ê–ù–ù–´–•\n")
    
    # –¢–µ—Å—Ç 1: –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –≥–æ—Ä–æ–¥–æ–≤
    print("=" * 60)
    print("üìç –¢–ï–°–¢ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –≥–æ—Ä–æ–¥–æ–≤ (–£–∫—Ä–∞–∏–Ω–∞)\n")
    
    cities_ua = load_geonames_db('UA')
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≥–æ—Ä–æ–¥–æ–≤ –£–∫—Ä–∞–∏–Ω—ã: {len(cities_ua)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫—Ä—É–ø–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤
    expected_cities = ['kyiv', 'kiev', 'odesa', 'odessa', 'lviv', 'kharkiv', 'dnipro']
    found_cities = [city for city in expected_cities if city in cities_ua]
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤: {len(found_cities)}/{len(expected_cities)}")
    print(f"   –ü—Ä–∏–º–µ—Ä—ã: {', '.join(list(cities_ua)[:10])}")
    
    if len(cities_ua) < 100:
        print("‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ú–∞–ª–æ –≥–æ—Ä–æ–¥–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–æ!")
    
    print()
    
    # –¢–µ—Å—Ç 2: –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –±—Ä–µ–Ω–¥–æ–≤
    print("=" * 60)
    print("üè∑Ô∏è –¢–ï–°–¢ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –±—Ä–µ–Ω–¥–æ–≤\n")
    
    brands = load_brands_db()
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –±—Ä–µ–Ω–¥–æ–≤: {len(brands)}")
    print(f"   –ü—Ä–∏–º–µ—Ä—ã: {', '.join(list(brands)[:15])}")
    
    if len(brands) < 30:
        print("‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ú–∞–ª–æ –±—Ä–µ–Ω–¥–æ–≤ –≤ –±–∞–∑–µ!")
    
    print()
    
    # –¢–µ—Å—Ç 3: –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è
    print("=" * 60)
    print("üìù –¢–ï–°–¢ 3: –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤\n")
    
    lemma_tests = [
        ('–∫–∏–µ–≤—É', '–∫–∏–µ–≤'),
        ('–∫–∏—î–≤—ñ', '–∫–∏—ó–≤'),
        ('–æ–¥–µ—Å—Å–µ', '–æ–¥–µ—Å—Å–∞'),
        ('–ø—ã–ª–µ—Å–æ—Å–æ–≤', '–ø—ã–ª–µ—Å–æ—Å'),
        ('samsung', 'samsung'),  # –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ —Å–ª–æ–≤–æ
    ]
    
    passed = 0
    for word, expected_lemma in lemma_tests:
        lemma = get_lemma(word)
        if lemma == expected_lemma:
            print(f"‚úÖ '{word}' ‚Üí '{lemma}'")
            passed += 1
        else:
            print(f"‚ö†Ô∏è '{word}' ‚Üí '{lemma}' (–æ–∂–∏–¥–∞–ª–æ—Å—å: '{expected_lemma}')")
    
    print(f"\nüìä –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è: {passed}/{len(lemma_tests)} —É—Å–ø–µ—à–Ω–æ")
    print()
    
    # –¢–µ—Å—Ç 4: –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –≥–æ—Ä–æ–¥–æ–≤
    print("=" * 60)
    print("üîç –¢–ï–°–¢ 4: –ü–æ–∏—Å–∫ –≥–æ—Ä–æ–¥–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ\n")
    
    search_tests = [
        ('kyiv', True, '–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (EN)'),
        ('kiev', True, '–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ'),
        ('–∫–∏—ó–≤', True, '–£–∫—Ä–∞–∏–Ω—Å–∫–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ'),
        ('–æ–¥–µ—Å—Å–∞', True, '–†—É—Å—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ'),
        ('–∞–±–≤–≥–¥', False, '–ù–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –≥–æ—Ä–æ–¥'),
    ]
    
    passed = 0
    for query, should_find, description in search_tests:
        found = search_in_db(query, cities_ua, use_lemma=True)
        
        if found == should_find:
            status = "‚úÖ PASS"
            passed += 1
        else:
            status = "‚ùå FAIL"
        
        print(f"{status}: {description}")
        print(f"   Query: '{query}' ‚Üí Found: {found}")
    
    print(f"\nüìä –ü–æ–∏—Å–∫ –≥–æ—Ä–æ–¥–æ–≤: {passed}/{len(search_tests)} —É—Å–ø–µ—à–Ω–æ")
    print()
    
    # –¢–µ—Å—Ç 5: –ü–æ–∏—Å–∫ –±—Ä–µ–Ω–¥–æ–≤
    print("=" * 60)
    print("üîç –¢–ï–°–¢ 5: –ü–æ–∏—Å–∫ –±—Ä–µ–Ω–¥–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ\n")
    
    brand_tests = [
        ('samsung', ['samsung'], '–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ'),
        ('lg dyson', ['lg', 'dyson'], '–î–≤–∞ –±—Ä–µ–Ω–¥–∞'),
        ('—Å–∞–º—Å—É–Ω–≥', [], '–†—É—Å—Å–∫–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ (–º–æ–∂–µ—Ç –Ω–µ –Ω–∞–π—Ç–∏)'),
        ('xiaomi dreame', ['xiaomi', 'dreame'], 'Brand collision'),
    ]
    
    passed = 0
    for text, expected, description in brand_tests:
        found = find_brands_in_text(text, brands)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–∞—à–ª–∏ —Ö–æ—Ç—è –±—ã —Ç–µ –±—Ä–µ–Ω–¥—ã –∫–æ—Ç–æ—Ä—ã–µ –æ–∂–∏–¥–∞–ª–∏
        all_found = all(brand in found for brand in expected)
        
        if all_found:
            status = "‚úÖ PASS"
            passed += 1
        else:
            status = "‚ö†Ô∏è PARTIAL" if len(found) > 0 else "‚ùå FAIL"
        
        print(f"{status}: {description}")
        print(f"   Text: '{text}'")
        print(f"   Found: {found}")
        print(f"   Expected: {expected}")
    
    print(f"\nüìä –ü–æ–∏—Å–∫ –±—Ä–µ–Ω–¥–æ–≤: {passed}/{len(brand_tests)} –ø–æ–ª–Ω–æ—Å—Ç—å—é —É—Å–ø–µ—à–Ω–æ")
    print()
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("=" * 60)
    print("\n‚úÖ –ú–û–î–£–õ–¨ –ë–ê–ó –î–ê–ù–ù–´–• –ì–û–¢–û–í –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ")
    print(f"üìä –ì–æ—Ä–æ–¥–∞: {len(cities_ua)} –∑–∞–ø–∏—Å–µ–π")
    print(f"üìä –ë—Ä–µ–Ω–¥—ã: {len(brands)} –∑–∞–ø–∏—Å–µ–π")
    
    return True


if __name__ == "__main__":
    run_tests()

"""
Batch Post-Filter v8.1 - CRITICAL FIX: Seed Protection
BUILD: 2026-01-17-01:30

üî• –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï v8.1:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
–ü–†–û–ë–õ–ï–ú–ê v8.0:
  - Seed protection (—Å—Ç—Ä–æ–∫–∏ 427-433) –ø—Ä–æ–ø—É—Å–∫–∞–ª–∞ –≥–æ—Ä–æ–¥–∞ –∏–∑ seed
  - –ï—Å–ª–∏ seed = "—Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤ –∂–¥–∞–Ω–æ–≤–∏—á–∏"
  - –¢–æ —Å–ª–æ–≤–æ "–∂–¥–∞–Ω–æ–≤–∏—á–∏" –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑—Ä–µ—à–∞–ª–æ—Å—å
  - –†–µ–∑—É–ª—å—Ç–∞—Ç: –ë–õ–û–ö–ò–†–û–í–ö–ê –ù–ï –†–ê–ë–û–¢–ê–õ–ê

–†–ï–®–ï–ù–ò–ï v8.1:
  - Seed protection —Ç–µ–ø–µ—Ä—å –ù–ï –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫ –≥–æ—Ä–æ–¥–∞–º
  - –ï—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–∞–π–¥–µ–Ω–æ –≤ all_cities_global –ò —Å—Ç—Ä–∞–Ω–∞ != target
  - –¢–æ –æ–Ω–æ –ë–õ–û–ö–ò–†–£–ï–¢–°–Ø –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–ª–∏—á–∏—è –≤ seed
  - Seed protection –æ—Å—Ç–∞—ë—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–∞–π–æ–Ω–æ–≤ —Ü–µ–ª–µ–≤–æ–π —Å—Ç—Ä–∞–Ω—ã
  
‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢:
  - "—Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤ –∂–¥–∞–Ω–æ–≤–∏—á–∏" ‚Üí –ë–õ–û–ö–ò–†–£–ï–¢–°–Ø (BY != UA)
  - "–∫–∏–µ–≤ —Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤" ‚Üí —Ä–∞–∑—Ä–µ—à–∞–µ—Ç—Å—è (seed city = UA)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Base: v8.0 TWO-LEVEL GEO DATABASE SUPPORT
"""

import re
import logging
import time
from typing import List, Dict, Set, Tuple, Optional
from collections import Counter

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger("BatchPostFilter")


class BatchPostFilter:
    def __init__(self, 
                 all_cities_global: Dict[str, str], 
                 forbidden_geo: Set[str], 
                 districts: Optional[Dict[str, str]] = None,
                 population_threshold: int = 5000):
        """
        v8.1 Constructor
        
        Args:
            all_cities_global: Dict {city_name: country_code} (lowercase)
            forbidden_geo: Set of forbidden locations (–ö—Ä—ã–º/–û–†–î–õ–û - lemmatized)
            districts: Optional Dict {district_name: country_code}
            population_threshold: Minimum city population to consider (default: 5000)
        """
        self.forbidden_geo = forbidden_geo
        self.districts = districts or {}
        self.population_threshold = population_threshold
        
        # v8.1: –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –±–∞–∑–∞ –≥–æ—Ä–æ–¥–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å lowercase
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        self.all_cities_global = {}
        for city, country in all_cities_global.items():
            normalized_city = str(city).lower().strip()
            normalized_country = str(country).lower().strip()
            if normalized_city and normalized_country:
                self.all_cities_global[normalized_city] = normalized_country
        
        logger.warning(f"üîç v8.1: Loaded {len(self.all_cities_global)} cities (normalized)")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏
        self.city_abbreviations = self._get_city_abbreviations()
        self.regions = self._get_regions()
        self.countries = self._get_countries()
        self.manual_small_cities = self._get_manual_small_cities()
        
        # Ignored words - –æ–±—ã—á–Ω—ã–µ —Å–ª–æ–≤–∞ –∫–æ—Ç–æ—Ä—ã–µ –ù–ï —è–≤–ª—è—é—Ç—Å—è –≥–æ—Ä–æ–¥–∞–º–∏
        self.ignored_words = {
            "–¥–æ–º",      # Ghana (GH) - "–≤—ã–µ–∑–¥ –Ω–∞ –¥–æ–º"
            "–º–∏—Ä",      # Russia villages - "–º–∏—Ä —Ü–µ–Ω"
            "–±–æ—Ä",      # Serbia - "—Å–æ—Å–Ω–æ–≤—ã–π –±–æ—Ä"  
            "–Ω–∏–≤–∞",     # Villages - "–∞–≤—Ç–æ–º–æ–±–∏–ª—å –Ω–∏–≤–∞"
            "–±–∞–ª–∫–∞",    # Villages - "–æ–≤—Ä–∞–∂–Ω–∞—è –±–∞–ª–∫–∞"
            "–ª—É—á",      # Villages - "—Å–æ–ª–Ω–µ—á–Ω—ã–π –ª—É—á"
            "—Å–ø—É—Ç–Ω–∏–∫",  # Villages - "—Å–ø—É—Ç–Ω–∏–∫–æ–≤–æ–µ —Ç–≤"
            "—Ä–∞–±–æ—Ç–∞",   # –ú–æ–∂–µ—Ç –±—ã—Ç—å –≥–æ—Ä–æ–¥–æ–º - "–∏—â—É —Ä–∞–±–æ—Ç—É"
            "—Ü–µ–Ω–∞",     # –ú–æ–∂–µ—Ç –±—ã—Ç—å –≥–æ—Ä–æ–¥–æ–º - "–ª—É—á—à–∞—è —Ü–µ–Ω–∞"
            "–≤—ã–µ–∑–¥",    # –ú–æ–∂–µ—Ç –±—ã—Ç—å –≥–æ—Ä–æ–¥–æ–º - "–≤—ã–µ–∑–¥ –º–∞—Å—Ç–µ—Ä–∞"
        }
        
        # üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –¢–ï–°–¢ v8.1
        logger.error("="*60)
        logger.error("üî• v8.1 CRITICAL TEST - Problem Cities Check")
        logger.error("="*60)
        
        test_problem_cities = {
            '–∂–¥–∞–Ω–æ–≤–∏—á–∏': 'by',
            '–∂–¥–∞–Ω–æ–≤–∏—á': 'by',
            '–±–∞—Ä–∞–Ω–æ–≤–∏—á–∏': 'by',
            '–ª–æ—à–∏—Ü–∞': 'by',
            '–∞–∫—Ç–æ–±–µ': 'kz',
            '—Ç–∞–ª–¥—ã–∫–æ—Ä–≥–∞–Ω': 'kz',
        }
        
        all_ok = True
        for city, expected in test_problem_cities.items():
            in_dict = city in self.all_cities_global
            actual = self.all_cities_global.get(city, 'NOT_FOUND')
            status = "‚úÖ" if (in_dict and actual == expected) else "‚ùå"
            
            if not (in_dict and actual == expected):
                all_ok = False
            
            logger.error(f"{status} '{city}': in_dict={in_dict}, value={actual}, expected={expected}")
        
        if all_ok:
            logger.error("üöÄ ‚úÖ ALL TESTS PASSED - Filter is READY")
        else:
            logger.error("‚ö†Ô∏è ‚ùå SOME TESTS FAILED")
        
        logger.error("="*60)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pymorphy3
        try:
            import pymorphy3
            self.morph_ru = pymorphy3.MorphAnalyzer(lang='ru')
            self.morph_uk = pymorphy3.MorphAnalyzer(lang='uk')
            self._has_morph = True
            logger.info("‚úÖ Pymorphy3 initialized for v8.1")
        except ImportError:
            logger.error("‚ùå Pymorphy3 not found!")
            self._has_morph = False
    
    def _get_city_abbreviations(self) -> Dict[str, str]:
        """–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è –≥–æ—Ä–æ–¥–æ–≤"""
        return {
            # –†–§
            '–µ–∫–±': 'ru', '–µ–∫–∞—Ç': 'ru',  # –ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥
            '—Å–ø–±': 'ru', '–ø–∏—Ç–µ—Ä': 'ru',  # –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥
            '–º—Å–∫': 'ru',  # –ú–æ—Å–∫–≤–∞
            '–Ω—Å–∫': 'ru',  # –ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫
            '–Ω–Ω': 'ru', '–Ω–Ω–æ–≤': 'ru',  # –ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥
            '–≤–ª–∞–¥': 'ru',  # –í–ª–∞–¥–∏–≤–æ—Å—Ç–æ–∫
            '—Ä–æ—Å—Ç–æ–≤': 'ru',  # –†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É
            '–∫—Ä–∞—Å–Ω–æ–¥–∞—Ä': 'ru',
            
            # BY
            '–º–Ω': 'by',  # –ú–∏–Ω—Å–∫
            
            # KZ
            '–∞–ª–º–∞—Ç—ã': 'kz',
            '–∞—Å—Ç–∞–Ω–∞': 'kz',
            
            # UZ
            '—Ç–∞—à–∫–µ–Ω—Ç': 'uz',
        }
    
    def _get_regions(self) -> Dict[str, str]:
        """–†–µ–≥–∏–æ–Ω—ã –†–§, BY, KZ, UZ"""
        return {
            # –†–§ —Ä–µ–≥–∏–æ–Ω—ã/—Ä–µ—Å–ø—É–±–ª–∏–∫–∏
            '–∏–Ω–≥—É—à–µ—Ç–∏—è': 'ru',
            '—á–µ—á–Ω—è': 'ru', '—á–µ—á–µ–Ω—Å–∫–∞—è —Ä–µ—Å–ø—É–±–ª–∏–∫–∞': 'ru',
            '–¥–∞–≥–µ—Å—Ç–∞–Ω': 'ru',
            '—Ç–∞—Ç–∞—Ä—Å—Ç–∞–Ω': 'ru',
            '–±–∞—à–∫–æ—Ä—Ç–æ—Å—Ç–∞–Ω': 'ru',
            '—É–¥–º—É—Ä—Ç–∏—è': 'ru',
            '–º–æ—Ä–¥–æ–≤–∏—è': 'ru',
            '–º–∞—Ä–∏–π —ç–ª': 'ru',
            '—á—É–≤–∞—à–∏—è': 'ru',
            '—è–∫—É—Ç–∏—è': 'ru', '—Å–∞—Ö–∞': 'ru',
            '–±—É—Ä—è—Ç–∏—è': 'ru',
            '—Ç—ã–≤–∞': 'ru',
            '—Ö–∞–∫–∞—Å–∏—è': 'ru',
            '–∞–ª—Ç–∞–π': 'ru',
            '–∫–∞—Ä–µ–ª–∏—è': 'ru',
            '–∫–æ–º–∏': 'ru',
            '–∫–∞–ª–º—ã–∫–∏—è': 'ru',
            '–∞–¥—ã–≥–µ—è': 'ru',
            '–∫–∞–±–∞—Ä–¥–∏–Ω–æ-–±–∞–ª–∫–∞—Ä–∏—è': 'ru',
            '–∫–∞—Ä–∞—á–∞–µ–≤–æ-—á–µ—Ä–∫–µ—Å–∏—è': 'ru',
            '—Å–µ–≤–µ—Ä–Ω–∞—è –æ—Å–µ—Ç–∏—è': 'ru',
            '–∫—Ä—ã–º': 'ru',
            
            # BY –æ–±–ª–∞—Å—Ç–∏
            '–±—Ä–µ—Å—Ç—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å': 'by',
            '–≤–∏—Ç–µ–±—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å': 'by',
            '–≥–æ–º–µ–ª—å—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å': 'by',
            '–≥—Ä–æ–¥–Ω–µ–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å': 'by',
            '–º–∏–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å': 'by',
            '–º–æ–≥–∏–ª—ë–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å': 'by',
            
            # KZ –æ–±–ª–∞—Å—Ç–∏
            '–∞–∫–º–æ–ª–∏–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å': 'kz',
            '–∞–∫—Ç—é–±–∏–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å': 'kz',
            '–∞–ª–º–∞—Ç–∏–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å': 'kz',
            '–≤–æ—Å—Ç–æ—á–Ω–æ-–∫–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å': 'kz',
        }
    
    def _get_countries(self) -> Dict[str, str]:
        """–°—Ç—Ä–∞–Ω—ã –º–∏—Ä–∞"""
        return {
            # –°–ù–ì
            '—Ä–æ—Å—Å–∏—è': 'ru', 'russia': 'ru', '—Ä—Ñ': 'ru',
            '–±–µ–ª–∞—Ä—É—Å—å': 'by', 'belarus': 'by', '–±–µ–ª–æ—Ä—É—Å—Å–∏—è': 'by',
            '–∫–∞–∑–∞—Ö—Å—Ç–∞–Ω': 'kz', 'kazakhstan': 'kz',
            '—É–∑–±–µ–∫–∏—Å—Ç–∞–Ω': 'uz', 'uzbekistan': 'uz',
            
            # –ï–≤—Ä–æ–ø–∞
            '–ø–æ–ª—å—à–∞': 'pl', 'poland': 'pl',
            '–ª–∏—Ç–≤–∞': 'lt', 'lithuania': 'lt',
            '–ª–∞—Ç–≤–∏—è': 'lv', 'latvia': 'lv',
            '—ç—Å—Ç–æ–Ω–∏—è': 'ee', 'estonia': 'ee',
            
            # –î—Ä—É–≥–∏–µ
            '–∏–∑—Ä–∞–∏–ª—å': 'il', 'israel': 'il',
            '—Ç—É—Ä—Ü–∏—è': 'tr', 'turkey': 'tr',
        }
    
    def _get_manual_small_cities(self) -> Dict[str, str]:
        """–ú–∞–ª—ã–µ –≥–æ—Ä–æ–¥–∞ –°–ù–ì"""
        return {
            # BY –º–∞–ª—ã–µ –≥–æ—Ä–æ–¥–∞
            '—Ñ–∞–Ω–∏–ø–æ–ª—å': 'by', '—Ñ–∞–Ω–∏–ø–∞–ª—å': 'by', 'fanipol': 'by',
            '–æ—à–º—è–Ω—ã': 'by', 'ashmyany': 'by',
            '—É–∑–¥–∞': 'by', 'uzda': 'by',
            
            # KZ –º–∞–ª—ã–µ –≥–æ—Ä–æ–¥–∞
            '—É–∑—ã–Ω–∞–≥–∞—à': 'kz', 'uzynagash': 'kz',
            '–æ—à': 'kg',  # –ö—ã—Ä–≥—ã–∑—Å—Ç–∞–Ω
        }
    
    def filter_batch(self, keywords: List[str], seed: str, country: str, language: str) -> Dict:
        """
        v8.1: Batch filtering with FIXED seed protection
        
        üî• –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï v8.1:
        Seed protection –ù–ï –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫ –≥–æ—Ä–æ–¥–∞–º –∏–∑ –¥—Ä—É–≥–∏—Ö —Å—Ç—Ä–∞–Ω!
        """
        start_time = time.time()
        
        stats = {
            'total': len(keywords),
            'allowed': 0,
            'blocked': 0,
            'reasons': Counter()
        }
        
        final_keywords = []
        final_anchors = []
        
        # Extract words from keywords for batch lemmatization
        all_words = set()
        for kw in keywords:
            words = re.findall(r'[–∞-—è—ëa-z0-9-]+', kw.lower())
            all_words.update(words)
        
        # Batch lemmatization
        lemmas_map = self._batch_lemmatize(all_words, language)
        
        # Extract seed cities ONLY from target country
        seed_cities = self._extract_cities_from_seed(seed, country, language)
        
        logger.info(f"[v8.1] Extracted {len(seed_cities)} seed cities from target country: {seed_cities}")
        
        # Process each keyword
        for keyword in keywords:
            is_ok, reason, reason_tag = self._check_geo_conflicts_v81(
                keyword, country, lemmas_map, seed_cities, language
            )
            
            if is_ok:
                final_keywords.append(keyword)
                stats['allowed'] += 1
            else:
                final_anchors.append(keyword)
                stats['blocked'] += 1
                stats['reasons'][reason_tag] += 1
                
                # Debug logging –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤
                if any(city in keyword.lower() for city in ['–∂–¥–∞–Ω–æ–≤–∏—á–∏', '–ª–æ—à–∏—Ü–∞', '–±–∞—Ä–∞–Ω–æ–≤–∏—á–∏']):
                    logger.warning(f"[v8.1] ‚öì BLOCKED (EXPECTED): '{keyword}' ‚Üí {reason}")
        
        elapsed = time.time() - start_time
        logger.info(f"[v8.1] Finished in {elapsed:.2f}s. {stats['allowed']} OK / {stats['blocked']} Blocked")
        
        return {
            'keywords': final_keywords,
            'anchors': final_anchors,
            'stats': {
                'total': stats['total'],
                'allowed': stats['allowed'],
                'blocked': stats['blocked'],
                'reasons': dict(stats['reasons']),
                'elapsed_time': round(elapsed, 2)
            }
        }

    def _check_geo_conflicts_v81(self, keyword: str, country: str, 
                                  lemmas_map: Dict[str, str], seed_cities: Set[str],
                                  language: str) -> Tuple[bool, str, str]:
        """
        v8.1: –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï - Seed protection –ù–ï —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –≥–æ—Ä–æ–¥–æ–≤
        
        –°–¢–ê–†–ê–Ø –õ–û–ì–ò–ö–ê v8.0 (–ù–ï–ü–†–ê–í–ò–õ–¨–ù–ê–Ø):
          if —Å–ª–æ–≤–æ_–≤_seed_cities ‚Üí auto-allow
          
        –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê v8.1 (–ü–†–ê–í–ò–õ–¨–ù–ê–Ø):
          if —Å–ª–æ–≤–æ_–≤_–±–∞–∑–µ_–≥–æ—Ä–æ–¥–æ–≤ AND —Å—Ç—Ä–∞–Ω–∞ != target:
             –ë–õ–û–ö–ò–†–£–ï–ú –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç seed!
          
          Seed protection –æ—Å—Ç–∞—ë—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–∞–π–æ–Ω–æ–≤ –°–í–û–ï–ô —Å—Ç—Ä–∞–Ω—ã
        """
        words = re.findall(r'[–∞-—è—ëa-z0-9-]+', keyword.lower())
        if not words:
            return True, "", ""

        keyword_lemmas = [lemmas_map.get(w, w) for w in words]
        
        # --- 1. HARD-BLACKLIST (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç #1) ---
        for check_val in words + keyword_lemmas:
            if check_val in self.forbidden_geo:
                return False, f"Hard-Blacklist '{check_val}'", "hard_blacklist"

        # --- 2. –†–ê–ô–û–ù–´ (—Å seed protection) ---
        # Seed protection —Ä–∞–±–æ—Ç–∞–µ—Ç –¢–û–õ–¨–ö–û –¥–ª—è —Ä–∞–π–æ–Ω–æ–≤ —Å–≤–æ–µ–π —Å—Ç—Ä–∞–Ω—ã
        words_set = set(words + keyword_lemmas)
        for w in words:
            if w in self.districts:
                dist_country = self.districts[w]
                
                # –ï—Å–ª–∏ —ç—Ç–æ —Ä–∞–π–æ–Ω –ù–ê–®–ï–ô —Å—Ç—Ä–∞–Ω—ã –ò –æ–Ω –µ—Å—Ç—å –≤ seed ‚Üí —Ä–∞–∑—Ä–µ—à–∞–µ–º
                if dist_country == country.lower() and w in seed_cities:
                    logger.debug(f"[v8.1] District '{w}' in seed_cities ‚Üí ALLOWED")
                    continue
                
                # –ï—Å–ª–∏ —ç—Ç–æ —Ä–∞–π–æ–Ω –ß–£–ñ–û–ô —Å—Ç—Ä–∞–Ω—ã ‚Üí –±–ª–æ–∫–∏—Ä—É–µ–º
                if dist_country != country.lower():
                    return False, f"—Ä–∞–π–æ–Ω '{w}' ({dist_country})", "districts"
        
        # --- 3. –°–û–ö–†–ê–©–ï–ù–ò–Ø –ì–û–†–û–î–û–í ---
        for w in words + keyword_lemmas:
            if w in self.city_abbreviations:
                abbr_country = self.city_abbreviations[w]
                if abbr_country != country.lower():
                    return False, f"—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ '{w}' ({abbr_country})", f"{abbr_country}_abbreviations"
        
        # --- 4. –†–ï–ì–ò–û–ù–´ ---
        check_regions = words + keyword_lemmas + self._extract_ngrams(words, 2)
        for item in check_regions:
            if item in self.regions:
                region_country = self.regions[item]
                if region_country != country.lower():
                    return False, f"—Ä–µ–≥–∏–æ–Ω '{item}' ({region_country})", f"{region_country}_regions"
        
        # --- 5. –°–¢–†–ê–ù–´ ---
        for w in words + keyword_lemmas:
            if w in self.countries:
                ctry_code = self.countries[w]
                if ctry_code != country.lower():
                    return False, f"—Å—Ç—Ä–∞–Ω–∞ '{w}' ({ctry_code})", f"{ctry_code}_countries"
        
        # --- 6. –ú–ê–õ–´–ï –ì–û–†–û–î–ê –°–ù–ì ---
        for w in words + keyword_lemmas:
            if w in self.manual_small_cities:
                city_country = self.manual_small_cities[w]
                if city_country == 'unknown':
                    return False, f"–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –æ–±—ä–µ–∫—Ç '{w}'", "unknown"
                if city_country != country.lower():
                    return False, f"–º–∞–ª—ã–π –≥–æ—Ä–æ–¥ '{w}' ({city_country})", f"{city_country}_small_cities"

        # --- 7. –ì–û–†–û–î–ê (–ì–õ–ê–í–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê) ---
        # üî• v8.1 –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: 
        # Seed protection –ù–ï –†–ê–ë–û–¢–ê–ï–¢ –¥–ª—è –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ –¥—Ä—É–≥–∏—Ö —Å—Ç—Ä–∞–Ω!
        
        search_items = []
        search_items.extend(words)
        search_items.extend(keyword_lemmas)
        
        # –ë–∏–≥—Ä–∞–º–º—ã
        bigrams = self._extract_ngrams(words, 2)
        search_items.extend(bigrams)
        search_items.extend([bg.replace(' ', '-') for bg in bigrams])
        
        lemma_bigrams = self._extract_ngrams(keyword_lemmas, 2)
        search_items.extend(lemma_bigrams)
        search_items.extend([bg.replace(' ', '-') for bg in lemma_bigrams])
        
        # –¢—Ä–∏–≥—Ä–∞–º–º—ã
        trigrams = self._extract_ngrams(words, 3)
        search_items.extend(trigrams)
        search_items.extend([tg.replace(' ', '-') for tg in trigrams])

        for item in search_items:
            if len(item) < 3:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º ignored_words
            if item in self.ignored_words:
                logger.debug(f"[v8.1] '{item}' in ignored_words, skipping")
                continue
            
            # Debug –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤
            debug_cities = ['–∂–¥–∞–Ω–æ–≤–∏—á–∏', 'zhdanovichi', '–∂–¥–∞–Ω–æ–≤–∏—á', '–ª–æ—à–∏—Ü–∞', 'losica', '–±–∞—Ä–∞–Ω–æ–≤–∏—á–∏']
            is_debug_city = any(dc in item.lower() for dc in debug_cities)
            
            if is_debug_city:
                logger.warning(f"üîç [v8.1 DEBUG] Processing '{item}'")
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ (—Å–∫–ª–æ–Ω–µ–Ω–∏—è ‚Üí –±–∞–∑–æ–≤–∞—è —Ñ–æ—Ä–º–∞)
            item_normalized = self._get_lemma(item, language)
            
            if is_debug_city:
                logger.warning(f"üîç [v8.1 DEBUG] Normalized: '{item}' ‚Üí '{item_normalized}'")
            
            # –ò—â–µ–º –≤ –±–∞–∑–µ
            found_country = self.all_cities_global.get(item_normalized)
            
            if is_debug_city:
                logger.warning(f"üîç [v8.1 DEBUG] Lookup (normalized): '{item_normalized}' ‚Üí {found_country}")
            
            if not found_country:
                # –ü—Ä–æ–±—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
                found_country = self.all_cities_global.get(item)
                
                if is_debug_city:
                    logger.warning(f"üîç [v8.1 DEBUG] Lookup (original): '{item}' ‚Üí {found_country}")
                
                if found_country:
                    item_normalized = item
            
            # ========== –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –õ–û–ì–ò–ö–ê v8.1 ==========
            if found_country:
                if is_debug_city:
                    logger.warning(f"üîç [v8.1 DEBUG] FOUND: '{item_normalized}' = {found_country.upper()}")
                    logger.warning(f"üîç [v8.1 DEBUG] Target: {country.lower()}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –≠—Ç–æ –Ω–∞—à —Ü–µ–ª–µ–≤–æ–π –≥–æ—Ä–æ–¥?
                if found_country == country.lower():
                    logger.debug(f"[v8.1] City '{item_normalized}' ({found_country}) - ALLOWED (target country)")
                    continue
                
                # üî• –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï v8.1:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: Seed protection –£–î–ê–õ–ï–ù–ê –¥–ª—è –≥–æ—Ä–æ–¥–æ–≤!
                # 
                # –°–¢–ê–†–´–ô –ö–û–î v8.0 (–ù–ï–ü–†–ê–í–ò–õ–¨–ù–û):
                # if item_normalized in seed_cities:
                #     logger.debug(f"City '{item_normalized}' in seed_cities - ALLOWED")
                #     continue
                #
                # –ù–û–í–´–ô –ö–û–î v8.1 (–ü–†–ê–í–ò–õ–¨–ù–û):
                # Seed protection –ù–ï —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ –¥—Ä—É–≥–∏—Ö —Å—Ç—Ä–∞–Ω
                # –ë–ª–æ–∫–∏—Ä—É–µ–º –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–ª–∏—á–∏—è –≤ seed!
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ 3: –ì–æ—Ä–æ–¥ –∏–∑ –¥—Ä—É–≥–æ–π —Å—Ç—Ä–∞–Ω—ã ‚Üí –ë–õ–û–ö–ò–†–£–ï–ú –í–°–ï–ì–î–ê
                if is_debug_city:
                    logger.warning(f"üîç [v8.1 DEBUG] ‚öì BLOCKING: '{item_normalized}' ({found_country.upper()} != {country.upper()})")
                
                logger.warning(f"[v8.1] ‚öì BLOCKING foreign city: '{item}' ‚Üí '{item_normalized}' ({found_country.upper()})")
                return False, f"{found_country.upper()} –≥–æ—Ä–æ–¥ '{item_normalized}'", f"{found_country}_cities"
            
            # ========== –ú–û–†–§–û–õ–û–ì–ò–Ø = –í–¢–û–†–ò–ß–ù–ê (—Ç–æ–ª—å–∫–æ –¥–ª—è —Å–ª–æ–≤ –í–ù–ï –±–∞–∑—ã) ==========
            else:
                # –°–ª–æ–≤–æ –Ω–µ –≤ –±–∞–∑–µ –≥–æ—Ä–æ–¥–æ–≤ - –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –æ–±—ã—á–Ω–æ–µ —Å–ª–æ–≤–æ?
                if self._is_common_noun(item_normalized, language):
                    logger.debug(f"[v8.1] '{item_normalized}' NOT in geo database + common noun - ALLOWED")
                    continue
        
        # --- 8. –ì–†–ê–ú–ú–ê–¢–ò–ö–ê ---
        if not self._is_grammatically_valid(keyword, language):
            return False, "–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ñ–æ—Ä–º–∞", "grammar"
        
        return True, "", ""

    def _extract_cities_from_seed(self, seed: str, country: str, language: str) -> Set[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–æ—Ä–æ–¥–∞ –∏–∑ seed (–¢–û–õ–¨–ö–û –∏–∑ —Ü–µ–ª–µ–≤–æ–π —Å—Ç—Ä–∞–Ω—ã)"""
        if not self._has_morph:
            return set()
        
        seed_cities = set()
        words = re.findall(r'[–∞-—è—ëa-z0-9-]+', seed.lower())
        
        for word in words:
            if word in self.all_cities_global:
                city_country = self.all_cities_global[word]
                if city_country == country.lower():
                    seed_cities.add(word)
            
            lemma = self._get_lemma(word, language)
            if lemma in self.all_cities_global:
                city_country = self.all_cities_global[lemma]
                if city_country == country.lower():
                    seed_cities.add(lemma)
        
        bigrams = self._extract_ngrams(words, 2)
        for bigram in bigrams:
            if bigram in self.all_cities_global:
                city_country = self.all_cities_global[bigram]
                if city_country == country.lower():
                    seed_cities.add(bigram)
        
        return seed_cities

    def _batch_lemmatize(self, words: Set[str], language: str) -> Dict[str, str]:
        """Batch –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è"""
        if not self._has_morph:
            return {w: w for w in words}
        
        morph = self.morph_ru if language == 'ru' else self.morph_uk
        lemmas = {}
        
        for word in words:
            lemma = self._get_lemma(word, language, morph)
            lemmas[word] = lemma
        
        return lemmas

    def _get_lemma(self, word: str, language: str, morph=None) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –ª–µ–º–º—É —Å–ª–æ–≤–∞"""
        if not self._has_morph:
            return word
        
        if morph is None:
            morph = self.morph_ru if language == 'ru' else self.morph_uk
        
        try:
            parsed = morph.parse(word)
            if parsed:
                return parsed[0].normal_form
        except:
            pass
        
        return word

    def _extract_ngrams(self, words: List[str], n: int = 2) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç n-–≥—Ä–∞–º–º—ã"""
        if len(words) < n:
            return []
        return [" ".join(words[i:i+n]) for i in range(len(words) - n + 1)]

    def _is_grammatically_valid(self, keyword: str, language: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å"""
        if not self._has_morph or language not in ['ru', 'uk']:
            return True
        
        morph = self.morph_ru if language == 'ru' else self.morph_uk
        words = re.findall(r'[–∞-—è—ëa-z]+', keyword.lower())
        
        for word in words:
            try:
                parsed = morph.parse(word)
                if parsed:
                    tag = parsed[0].tag
                    invalid_tags = {'datv', 'ablt', 'loct'}
                    if 'plur' in tag and any(bad in tag for bad in invalid_tags):
                        return False
            except:
                pass
        
        return True

    def _is_common_noun(self, word: str, language: str) -> bool:
        """Smart disambiguation —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º Geox"""
        if not self._has_morph or language not in ['ru', 'uk']:
            return False
        
        morph = self.morph_ru if language == 'ru' else self.morph_uk
        
        try:
            parsed = morph.parse(word)
            if parsed:
                for parse_variant in parsed:
                    tag = parse_variant.tag
                    
                    if 'Geox' in tag:
                        logger.debug(f"[v8.1] '{word}' is Geox, NOT common noun")
                        return False
                    
                    if 'Name' in tag:
                        return False
                
                first_tag = parsed[0].tag
                if 'NOUN' in first_tag and word.islower():
                    logger.debug(f"[v8.1] '{word}' is common noun")
                    return True
        except:
            pass
        
        return False


# ============================================
# DISTRICTS
# ============================================

DISTRICTS_MINSK = {
    "—É—Ä—É—á—å–µ": "by",
    "—à–∞–±–∞–Ω—ã": "by",
    "–∫–∞–º–µ–Ω–Ω–∞—è –≥–æ—Ä–∫–∞": "by",
    "—Å–µ—Ä–µ–±—Ä—è–Ω–∫–∞": "by"
}

DISTRICTS_TASHKENT = {
    "—á–∏–ª–∞–Ω–∑–∞—Ä": "uz",
    "—é–Ω—É—Å–∞–±–∞–¥": "uz",
    "—Å–µ—Ä–≥–µ–ª–∏": "uz",
    "—è–∫–∫–∞—Å–∞—Ä–∞–π": "uz"
}

DISTRICTS_EXTENDED = {**DISTRICTS_MINSK, **DISTRICTS_TASHKENT}

"""
ChatGPT PPM TEST - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
PREFIX Projection Method —Å User-Agent –∏ –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏
"""

from fastapi import FastAPI, Query
from fastapi.middleware.cors import CORSMiddleware
from typing import List
from collections import Counter
import os
import httpx
import asyncio
import time
import random

app = FastAPI(title="ChatGPT PPM Test Fixed", version="1.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# User-Agent —Ä–æ—Ç–∞—Ü–∏—è
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
]

class AutocompleteParser:
    def __init__(self):
        self.base_url = "https://suggestqueries.google.com/complete/search"
    
    async def fetch_suggestions(self, query: str, country: str, language: str) -> List[str]:
        params = {"client": "chrome", "q": query, "gl": country, "hl": language}
        headers = {"User-Agent": random.choice(USER_AGENTS)}
        
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(self.base_url, params=params, headers=headers)
                if response.status_code == 200:
                    data = response.json()
                    if isinstance(data, list) and len(data) > 1:
                        return [s for s in data[1] if isinstance(s, str)]
                return []
        except Exception as e:
            print(f"Error: {e}")
            return []
    
    async def chatgpt_ppm_test(self, seed: str, country: str, language: str) -> List[str]:
        all_keywords = set()
        seed_words = set(seed.lower().split())
        
        print(f"\n{'='*60}")
        print(f"üî¨ ChatGPT PPM - PREFIX Projection Method (FIXED)")
        print(f"{'='*60}")
        print(f"Seed: '{seed}'")
        print(f"‚úÖ User-Agent —Ä–æ—Ç–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞")
        print(f"‚úÖ –ó–∞–¥–µ—Ä–∂–∫–∏ 1-2 —Å–µ–∫ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏\n")
        
        # –≠–¢–ê–ü 1: –ë–∞–∑–æ–≤—ã–π SUFFIX
        print(f"{'='*60}")
        print(f"–≠–¢–ê–ü 1: –ë–∞–∑–æ–≤—ã–π SUFFIX –ø–∞—Ä—Å–∏–Ω–≥")
        print(f"{'='*60}\n")
        
        alphabet = "–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è"
        suffix_results = []
        
        for letter in alphabet:
            query = f"{seed} {letter}"
            results = await self.fetch_suggestions(query, country, language)
            suffix_results.extend(results)
            await asyncio.sleep(random.uniform(1.0, 2.0))
        
        print(f"–ë–∞–∑–æ–≤—ã–π SUFFIX: 29 –∑–∞–ø—Ä–æ—Å–æ–≤")
        print(f"–ü–æ–ª—É—á–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(suffix_results)}\n")
        
        # –≠–¢–ê–ü 2: –û—Ç–±–æ—Ä —Ç–æ–ø-30 SUFFIX
        print(f"{'='*60}")
        print(f"–≠–¢–ê–ü 2: –û—Ç–±–æ—Ä —Ç–æ–ø-30 SUFFIX")
        print(f"{'='*60}\n")
        
        top_suffix = suffix_results[:30] if len(suffix_results) >= 30 else suffix_results
        
        print(f"–û—Ç–æ–±—Ä–∞–Ω–æ: {len(top_suffix)}")
        for s in top_suffix[:5]:
            print(f"  ‚Ä¢ {s}")
        print()
        
        # –≠–¢–ê–ü 3: –í—Ç–æ—Ä–∏—á–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        print(f"{'='*60}")
        print(f"–≠–¢–ê–ü 3: –í—Ç–æ—Ä–∏—á–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ (–∫–ª—é—á–µ–≤–æ–π —ç—Ç–∞–ø!)")
        print(f"{'='*60}\n")
        
        expansion_letters = ["–∞", "–±", "–≤", "–≥", "—Å", "–º", "–Ω", "–∫"]
        all_expansions = []
        expansion_count = 0
        
        for suffix_key in top_suffix:
            for letter in expansion_letters:
                query = f"{suffix_key} {letter}"
                results = await self.fetch_suggestions(query, country, language)
                all_expansions.extend(results)
                expansion_count += 1
                await asyncio.sleep(random.uniform(1.0, 2.0))
        
        print(f"–í—Ç–æ—Ä–∏—á–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ: {expansion_count} –∑–∞–ø—Ä–æ—Å–æ–≤")
        print(f"–ü–æ–ª—É—á–µ–Ω–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π: {len(all_expansions)}\n")
        
        # –≠–¢–ê–ü 4: –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ n-–≥—Ä–∞–º–º
        print(f"{'='*60}")
        print(f"–≠–¢–ê–ü 4: –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ n-–≥—Ä–∞–º–º")
        print(f"{'='*60}\n")
        
        bigrams = Counter()
        trigrams = Counter()
        
        for result in all_expansions:
            words = result.lower().split()
            
            # –ë–∏–≥—Ä–∞–º–º—ã
            for i in range(len(words) - 1):
                bigram = f"{words[i]} {words[i+1]}"
                if words[i] not in seed_words and words[i+1] not in seed_words:
                    bigrams[bigram] += 1
            
            # –¢—Ä–∏–≥—Ä–∞–º–º—ã
            for i in range(len(words) - 2):
                trigram = f"{words[i]} {words[i+1]} {words[i+2]}"
                if words[i] not in seed_words:
                    trigrams[trigram] += 1
        
        frequent_bigrams = {k: v for k, v in bigrams.items() if v >= 3}
        frequent_trigrams = {k: v for k, v in trigrams.items() if v >= 2}
        
        print(f"–ß–∞—Å—Ç–æ—Ç–Ω—ã—Ö –±–∏–≥—Ä–∞–º–º (‚â•3): {len(frequent_bigrams)}")
        print(f"–¢–æ–ø-10:")
        for bg, freq in sorted(frequent_bigrams.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  ‚Ä¢ '{bg}' ({freq} —Ä–∞–∑)")
        
        print(f"\n–ß–∞—Å—Ç–æ—Ç–Ω—ã—Ö —Ç—Ä–∏–≥—Ä–∞–º–º (‚â•2): {len(frequent_trigrams)}")
        print(f"–¢–æ–ø-10:")
        for tg, freq in sorted(frequent_trigrams.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  ‚Ä¢ '{tg}' ({freq} —Ä–∞–∑)")
        print()
        
        # –≠–¢–ê–ü 5: –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è
        print(f"{'='*60}")
        print(f"–≠–¢–ê–ü 5: –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è PREFIX")
        print(f"{'='*60}\n")
        
        prefix_candidates = set()
        projection_count = 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∏–≥—Ä–∞–º–º—ã
        for ngram in list(frequent_bigrams.keys())[:50]:
            test_query = f"{ngram} {seed}"
            results = await self.fetch_suggestions(test_query, country, language)
            projection_count += 1
            
            if results:
                prefix_candidates.add(ngram)
                print(f"‚úÖ '{ngram}' ‚Üí PREFIX –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω ({len(results)} –∫–ª—é—á–µ–π)")
            
            await asyncio.sleep(random.uniform(1.0, 2.0))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–∏–≥—Ä–∞–º–º—ã
        for ngram in list(frequent_trigrams.keys())[:20]:
            test_query = f"{ngram} {seed}"
            results = await self.fetch_suggestions(test_query, country, language)
            projection_count += 1
            
            if results:
                prefix_candidates.add(ngram)
                print(f"‚úÖ '{ngram}' ‚Üí PREFIX –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω ({len(results)} –∫–ª—é—á–µ–π)")
            
            await asyncio.sleep(random.uniform(1.0, 2.0))
        
        print(f"\n–ü—Ä–æ–µ–∫—Ü–∏—è: {projection_count} –∑–∞–ø—Ä–æ—Å–æ–≤")
        print(f"PREFIX –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(prefix_candidates)}\n")
        
        # –≠–¢–ê–ü 6: –°–±–æ—Ä —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π
        if len(prefix_candidates) > 0:
            print(f"{'='*60}")
            print(f"–≠–¢–ê–ü 6: –°–±–æ—Ä —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö PREFIX –∫–ª—é—á–µ–π")
            print(f"{'='*60}\n")
            
            for candidate in prefix_candidates:
                query = f"{candidate} {seed}"
                results = await self.fetch_suggestions(query, country, language)
                
                if results:
                    all_keywords.update(results)
                    print(f"'{candidate}' ‚Üí {len(results)} –∫–ª—é—á–µ–π")
                
                await asyncio.sleep(random.uniform(1.0, 2.0))
        
        # –°–¢–ê–¢–ò–°–¢–ò–ö–ê
        total_queries = 29 + expansion_count + projection_count
        
        print(f"\n{'='*60}")
        print(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê PPM")
        print(f"{'='*60}")
        print(f"SUFFIX: 29 –∑–∞–ø—Ä–æ—Å–æ–≤")
        print(f"–í—Ç–æ—Ä–∏—á–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ: {expansion_count} –∑–∞–ø—Ä–æ—Å–æ–≤")
        print(f"–ü—Ä–æ–µ–∫—Ü–∏—è: {projection_count} –∑–∞–ø—Ä–æ—Å–æ–≤")
        print(f"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        print(f"–í–°–ï–ì–û: {total_queries} –∑–∞–ø—Ä–æ—Å–æ–≤")
        print(f"")
        print(f"PREFIX –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(prefix_candidates)}")
        print(f"–§–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π: {len(all_keywords)}")
        print(f"")
        
        if len(all_keywords) > 0:
            print(f"üéâ PPM –†–ê–ë–û–¢–ê–ï–¢!")
            print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞—à–ª–∞ PREFIX!")
        else:
            print(f"‚ùå PPM –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        print(f"{'='*60}\n")
        
        return list(all_keywords)


@app.get("/api/test-parser/chatgpt-ppm")
async def test_chatgpt_ppm(
    seed: str = Query("—Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤"),
    country: str = Query("UA"),
    language: str = Query("ru")
):
    parser = AutocompleteParser()
    start = time.time()
    keywords = await parser.chatgpt_ppm_test(seed, country, language)
    return {
        "seed": seed,
        "method": "ChatGPT PPM (Fixed)",
        "keywords": keywords,
        "count": len(keywords),
        "time": round(time.time() - start, 2)
    }


@app.get("/")
async def root():
    return {
        "api": "ChatGPT PPM Test (Fixed)",
        "url": "/api/test-parser/chatgpt-ppm?seed=—Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤&country=UA&language=ru"
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=int(os.getenv("PORT", 8000)))

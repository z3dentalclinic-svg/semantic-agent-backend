"""
CSG (Context-Shift Graph) TEST
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –æ—Ç ChatGPT –¥–ª—è –ø–æ–∏—Å–∫–∞ PREFIX –∑–∞–ø—Ä–æ—Å–æ–≤

–¶–ï–õ–¨: –ù–∞–π—Ç–∏ "—Å–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä —Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤"

–ú–ï–¢–û–î CSG:
1. –ò—Å–ø–æ–ª—å–∑—É–µ–º —è–∫–æ—Ä—å (–≥–æ—Ä–æ–¥): "–∫–∏–µ–≤"
2. –î–µ–ª–∞–µ–º Context Shift: "–∫–∏–µ–≤ —Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤"
3. –í—Ç–æ—Ä–∏—á–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ: "–∫–∏–µ–≤ —Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤ —Å/—Å–µ/—Å–µ—Ä/—Å–µ—Ä–≤..."
4. –û–∂–∏–¥–∞–µ–º: "–∫–∏–µ–≤ —Å–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä —Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤"
5. –ò–∑–≤–ª–µ–∫–∞–µ–º: "—Å–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä"
6. –ü—Ä–æ–≤–µ—Ä—è–µ–º: "—Å–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä —Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤"
"""

from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Set
import os
import yaml
import httpx
import asyncio
import time
import random

# –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
try:
    import pymorphy3
    PYMORPHY_AVAILABLE = True
except ImportError:
    PYMORPHY_AVAILABLE = False
    print("‚ö†Ô∏è pymorphy3 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")

try:
    import inflect
    INFLECT_AVAILABLE = True
except ImportError:
    INFLECT_AVAILABLE = False
    print("‚ö†Ô∏è inflect –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")

app = FastAPI(title="Semantic Agent API", version="2.0.0")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Create google-ads.yaml from environment variables
def create_google_ads_config():
    """Create google-ads.yaml from environment variables"""
    config = {
        'developer_token': os.getenv('GOOGLE_ADS_DEVELOPER_TOKEN'),
        'client_id': os.getenv('GOOGLE_ADS_CLIENT_ID'),
        'client_secret': os.getenv('GOOGLE_ADS_CLIENT_SECRET'),
        'refresh_token': os.getenv('GOOGLE_ADS_REFRESH_TOKEN', ''),
        'login_customer_id': os.getenv('GOOGLE_ADS_CUSTOMER_ID'),
        'use_proto_plus': True
    }
    
    # Write to file
    with open('google-ads.yaml', 'w') as f:
        yaml.dump(config, f)
    
    return config

# ============================================
# GOOGLE AUTOCOMPLETE PARSER
# ============================================

class AutocompleteParser:
    """–ü–∞—Ä—Å–µ—Ä Google Autocomplete"""
    
    def __init__(self):
        self.base_url = "http://suggestqueries.google.com/complete/search"
        
        # –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (–¥–ª—è –≤—Å–µ—Ö —è–∑—ã–∫–æ–≤)
        self.base_modifiers = list("abcdefghijklmnopqrstuvwxyz0123456789")
        
        # –Ø–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã)
        self.language_modifiers = {
            'en': [],  # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π - —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ
            'ru': list("–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ç—é—è"),  # –†—É—Å—Å–∫–∏–π (29 –±—É–∫–≤ –±–µ–∑ —ë,—ä,—ã,—å)
            'uk': list("–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—å—é—è—ñ—ó—î“ë"),  # –£–∫—Ä–∞–∏–Ω—Å–∫–∏–π
            'de': list("√§√∂√º√ü"),  # –ù–µ–º–µ—Ü–∫–∏–π
            'fr': list("√†√¢√§√¶√ß√©√®√™√´√Ø√Æ√¥√π√ª√º√ø"),  # –§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π
            'es': list("√°√©√≠√±√≥√∫√º"),  # –ò—Å–ø–∞–Ω—Å–∫–∏–π
            'pl': list("ƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º"),  # –ü–æ–ª—å—Å–∫–∏–π
            'it': list("√†√®√©√¨√≠√Æ√≤√≥√π√∫"),  # –ò—Ç–∞–ª—å—è–Ω—Å–∫–∏–π
        }
        
        # –°–ø–∏—Å–æ–∫ —Ä–∞–∑–Ω—ã—Ö User-Agent –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/120.0.0.0",
        ]
        
        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
        self.morph_ru = None
        self.morph_en = None
        
        if PYMORPHY_AVAILABLE:
            try:
                self.morph_ru = pymorphy3.MorphAnalyzer()
                print("‚úÖ pymorphy3 (—Ä—É—Å—Å–∫–∏–π) –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ pymorphy3: {e}")
        
        if INFLECT_AVAILABLE:
            try:
                self.morph_en = inflect.engine()
                print("‚úÖ inflect (–∞–Ω–≥–ª–∏–π—Å–∫–∏–π) –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ inflect: {e}")
    
    def get_modifiers(self, language: str) -> List[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —è–∑—ã–∫–∞
        
        Args:
            language: –ö–æ–¥ —è–∑—ã–∫–∞ (en, ru, uk, de, fr, es, pl, it)
            
        Returns:
            List[str]: –ë–∞–∑–æ–≤—ã–µ (a-z + 0-9) + —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
        """
        modifiers = self.base_modifiers.copy()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        lang_mods = self.language_modifiers.get(language.lower(), [])
        modifiers.extend(lang_mods)
        
        return modifiers
        
    def get_word_forms_ru(self, word: str) -> Set[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—ã —Ä—É—Å—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞
        
        Args:
            word: –†—É—Å—Å–∫–æ–µ —Å–ª–æ–≤–æ
            
        Returns:
            Set[str]: –í—Å–µ —Ñ–æ—Ä–º—ã —Å–ª–æ–≤–∞ (–ø—ã–ª–µ—Å–æ—Å, –ø—ã–ª–µ—Å–æ—Å–∞, –ø—ã–ª–µ—Å–æ—Å—É, ...)
        """
        if not self.morph_ru:
            print(f"‚ö†Ô∏è morph_ru –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
            return {word}
        
        forms = set()
        try:
            parsed = self.morph_ru.parse(word)
            print(f"üîç –†–∞–∑–±–æ—Ä —Å–ª–æ–≤–∞ '{word}': –Ω–∞–π–¥–µ–Ω–æ {len(parsed)} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤")
            
            if parsed:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç —Ä–∞–∑–±–æ—Ä–∞
                p = parsed[0]
                print(f"üîç –ü–µ—Ä–≤—ã–π —Ä–∞–∑–±–æ—Ä: {p.tag}")
                
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–æ—Ä–º—ã –∏–∑ –ª–µ–∫—Å–µ–º—ã
                for form in p.lexeme:
                    forms.add(form.word)
                
                print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(forms)} —Ñ–æ—Ä–º: {list(forms)[:5]}...")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–æ—Ä–º –¥–ª—è '{word}': {e}")
            forms.add(word)
        
        if len(forms) == 0:
            print(f"‚ö†Ô∏è –ù–µ –ø–æ–ª—É—á–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π —Ñ–æ—Ä–º—ã –¥–ª—è '{word}', –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ")
            forms.add(word)
        
        return forms
    
    def get_word_forms_en(self, word: str) -> Set[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ñ–æ—Ä–º—ã –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞ (singular/plural)
        
        Args:
            word: –ê–Ω–≥–ª–∏–π—Å–∫–æ–µ —Å–ª–æ–≤–æ
            
        Returns:
            Set[str]: –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ
        """
        if not self.morph_en:
            return {word}
        
        forms = {word}
        try:
            # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ
            plural = self.morph_en.plural(word)
            if plural:
                forms.add(plural)
            
            # –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ (–µ—Å–ª–∏ –¥–∞–ª–∏ plural)
            singular = self.morph_en.singular_noun(word)
            if singular:
                forms.add(singular)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–æ—Ä–º –¥–ª—è '{word}': {e}")
        
        return forms
    
    def get_seed_variations(self, seed: str, language: str) -> List[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤–∞—Ä–∏–∞—Ü–∏–∏ seed —Ñ—Ä–∞–∑—ã —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º–∏ —Ñ–æ—Ä–º–∞–º–∏
        
        Args:
            seed: –ò—Å—Ö–æ–¥–Ω–∞—è —Ñ—Ä–∞–∑–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä "—Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤")
            language: –Ø–∑—ã–∫ (ru, en)
            
        Returns:
            List[str]: –í—Å–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ —Ñ—Ä–∞–∑—ã
        """
        print(f"üîç get_seed_variations –≤—ã–∑–≤–∞–Ω: seed='{seed}', language='{language}'")
        
        words = seed.split()
        print(f"üîç –°–ª–æ–≤ –≤ seed: {len(words)}")
        
        if len(words) < 2:
            print(f"‚ö†Ô∏è –ú–µ–Ω—å—à–µ 2 —Å–ª–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π seed")
            return [seed]
        
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–æ—Ä–º—ã –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ–≤–∞ (–æ–±—ã—á–Ω–æ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ)
        last_word = words[-1]
        print(f"üîç –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–ª–æ–≤–æ: '{last_word}'")
        
        if language.lower() == 'ru':
            print(f"üîç –í—ã–∑—ã–≤–∞–µ–º get_word_forms_ru('{last_word}')")
            word_forms = self.get_word_forms_ru(last_word)
            print(f"üîç –ü–æ–ª—É—á–µ–Ω–æ —Ñ–æ—Ä–º –æ—Ç get_word_forms_ru: {len(word_forms)}")
        elif language.lower() == 'en':
            print(f"üîç –í—ã–∑—ã–≤–∞–µ–º get_word_forms_en('{last_word}')")
            word_forms = self.get_word_forms_en(last_word)
            print(f"üîç –ü–æ–ª—É—á–µ–Ω–æ —Ñ–æ—Ä–º –æ—Ç get_word_forms_en: {len(word_forms)}")
        else:
            print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —è–∑—ã–∫ '{language}', –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π seed")
            return [seed]
        
        # –°–æ–∑–¥–∞–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏
        variations = []
        base = ' '.join(words[:-1])  # –≤—Å–µ —Å–ª–æ–≤–∞ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
        
        for form in word_forms:
            variations.append(f"{base} {form}")
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –≤–∞—Ä–∏–∞—Ü–∏–π: {len(variations)}")
        print(f"   –ü–µ—Ä–≤—ã–µ 3: {variations[:3]}")
        
        return variations
        
    async def fetch_suggestions(
        self, 
        query: str, 
        country: str = "US", 
        language: str = "en"
    ) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
        params = {
            "client": "firefox",
            "q": query,
            "gl": country.upper(),
            "hl": language.lower()
        }
        
        # –°–ª—É—á–∞–π–Ω—ã–π User-Agent –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        headers = {
            "User-Agent": random.choice(self.user_agents),
            "Accept": "application/json",
            "Accept-Language": f"{language.lower()},{language.lower()}-{country.upper()};q=0.9,en;q=0.8",
        }
        
        try:
            async with httpx.AsyncClient(timeout=10.0, headers=headers) as client:
                response = await client.get(self.base_url, params=params)
                response.raise_for_status()
                
                data = response.json()
                
                if len(data) >= 2 and isinstance(data[1], list):
                    return data[1]
                
                return []
                
        except Exception as e:
            print(f"‚ùå Error: {e}")
            return []
    
    async def parse_with_modifiers(
        self,
        seed: str,
        country: str = "US",
        language: str = "en",
        use_numbers: bool = False,
        use_morphology: bool = False
    ) -> List[str]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Å –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏ (SUFFIX + INFIX + MORPH)
        
        –ú–ï–¢–û–î 1: SUFFIX –ª–∞—Ç–∏–Ω–∏—Ü–∞/—Ü–∏—Ñ—Ä—ã - "seed –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä" (–ë–ï–ó –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏)
        –ú–ï–¢–û–î 2: SUFFIX –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ - "seed_form –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä" (–° –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–µ–π –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
        –ú–ï–¢–û–î 3: INFIX –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ - "—Å–ª–æ–≤–æ1 –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–ª–æ–≤–æ2" (–ë–ï–ó –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏)
        """
        all_keywords = set()
        
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞
        all_modifiers = self.get_modifiers(language)
        
        # –ï—Å–ª–∏ use_numbers=False, —É–±–∏—Ä–∞–µ–º —Ü–∏—Ñ—Ä—ã –∏–∑ –±–∞–∑–æ–≤—ã—Ö
        if not use_numbers:
            all_modifiers = [m for m in all_modifiers if not m.isdigit()]
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü—É/—Ü–∏—Ñ—Ä—ã –∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—É
        language_specific = self.language_modifiers.get(language.lower(), [])
        cyrillic_modifiers = [m for m in all_modifiers if m in language_specific]
        latin_digit_modifiers = [m for m in all_modifiers if m not in language_specific]
        
        # –ú–û–†–§–û–õ–û–ì–ò–Ø –ó–ê–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–ê –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø PREFIX
        # Seed –≤–∞—Ä–∏–∞—Ü–∏–∏ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è
        # seed_variations = [seed]
        # if use_morphology:
        #     seed_variations = self.get_seed_variations(seed, language)
        #     print(f"üî§ MORPH mode: ENABLED | Seed variations: {len(seed_variations)}")
        #     for var in seed_variations[:5]:
        #         print(f"   - {var}")
        #     if len(seed_variations) > 5:
        #         print(f"   ... –∏ –µ—â—ë {len(seed_variations) - 5}")
        
        # –í–†–ï–ú–ï–ù–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω—ã–π seed
        seed_variations = [seed]
        if use_morphology:
            print(f"‚ö†Ô∏è MORPH mode: –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ï–ù–ê –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø PREFIX")
        
        seed_words = seed.split()
        
        print(f"üåç Language: {language.upper()}")
        print(f"üìä Modifiers: Latin/Digits={len(latin_digit_modifiers)}, Cyrillic={len(cyrillic_modifiers)}")
        print(f"üìç INFIX mode: {'ENABLED' if len(cyrillic_modifiers) > 0 and len(seed_words) >= 2 else 'DISABLED'}")
        print(f"üìç PREFIX mode: {'ENABLED' if len(cyrillic_modifiers) > 0 else 'DISABLED'}")
        
        # ========================================
        # CSG (CONTEXT-SHIFT GRAPH) TEST - –û–¢ CHATGPT
        # ========================================
        print(f"\n{'='*60}")
        print(f"üî¨ [–¢–ï–°–¢] CSG - CONTEXT-SHIFT GRAPH (–æ—Ç ChatGPT)")
        print(f"{'='*60}")
        print(f"–ò—Å—Ö–æ–¥–Ω—ã–π seed: '{seed}'")
        print(f"")
        print(f"–¶–ï–õ–¨: –ù–∞–π—Ç–∏ '—Å–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä —Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤'")
        print(f"")
        print(f"–ú–ï–¢–û–î CSG:")
        print(f"1. –Ø–∫–æ—Ä—å: '–∫–∏–µ–≤' (–≥–æ—Ä–æ–¥)")
        print(f"2. Context Shift: '–∫–∏–µ–≤ —Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤'")
        print(f"3. –í—Ç–æ—Ä–∏—á–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ: '–∫–∏–µ–≤ —Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤ —Å/—Å–µ/—Å–µ—Ä...'")
        print(f"4. –û–∂–∏–¥–∞–µ–º –≤—Å—Ç–∞–≤–∫—É: '–∫–∏–µ–≤ [—Å–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä] —Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤'")
        print(f"5. –ò–∑–≤–ª–µ–∫–∞–µ–º PREFIX: '—Å–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä'")
        print(f"")
        
        # ========================================
        # –≠–¢–ê–ü 0: –¢–µ—Å—Ç–æ–≤—ã–µ —è–∫–æ—Ä—è
        # ========================================
        test_anchors = ["–∫–∏–µ–≤", "–º–æ—Å–∫–≤–∞", "–∞—Å—Ç–∞–Ω–∞"]
        
        print(f"–¢–µ—Å—Ç–æ–≤—ã–µ —è–∫–æ—Ä—è: {', '.join(test_anchors)}\n")
        
        # ========================================
        # –≠–¢–ê–ü 1: Context Shift —Å —è–∫–æ—Ä—è–º–∏
        # ========================================
        print(f"{'='*60}")
        print(f"–≠–¢–ê–ü 1: Context Shift (—è–∫–æ—Ä—å + seed)")
        print(f"{'='*60}\n")
        
        context_shift_results = {}
        
        for anchor in test_anchors:
            context_query = f"{anchor} {seed}"
            context_suggestions = await self.fetch_suggestions(context_query, country, language)
            context_shift_results[anchor] = context_suggestions
            
            print(f"'{context_query}' ‚Üí {len(context_suggestions)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            if len(context_suggestions) > 0:
                for s in context_suggestions[:3]:
                    print(f"  ‚Ä¢ {s}")
            
            delay = random.uniform(0.5, 1.5)
            await asyncio.sleep(delay)
        
        print(f"\n‚úÖ Context Shift –∑–∞–≤–µ—Ä—à—ë–Ω\n")
        
        # ========================================
        # –≠–¢–ê–ü 2: –í—Ç–æ—Ä–∏—á–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ (–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –¢–ï–°–¢!)
        # ========================================
        print(f"{'='*60}")
        print(f"–≠–¢–ê–ü 2: –í—Ç–æ—Ä–∏—á–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ (–º–µ–∂–¥—É —è–∫–æ—Ä–µ–º –∏ seed)")
        print(f"{'='*60}")
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º: –º–æ–∂–µ—Ç –ª–∏ Google –≤—Å—Ç–∞–≤–∏—Ç—å —Å–ª–æ–≤–∞ –ú–ï–ñ–î–£ —è–∫–æ—Ä–µ–º –∏ seed?\n")
        
        # –¶–µ–ª–µ–≤—ã–µ –±—É–∫–≤—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ "—Å–µ—Ä–≤–∏—Å"
        target_letters = {
            "—Å": "–∏—â–µ–º '—Å–µ—Ä–≤–∏—Å', '—Å–µ—Ä–≤–∏—Å–Ω—ã–π', '—Å—Ä–æ—á–Ω—ã–π'",
            "—Å–µ": "–∏—â–µ–º '—Å–µ—Ä–≤–∏—Å', '—Å–µ—Ä–≤–∏—Å–Ω—ã–π'", 
            "—Å–µ—Ä": "–∏—â–µ–º '—Å–µ—Ä–≤–∏—Å', '—Å–µ—Ä–≤–∏—Å–Ω—ã–π'",
            "—Å–µ—Ä–≤": "–∏—â–µ–º '—Å–µ—Ä–≤–∏—Å', '—Å–µ—Ä–≤–∏—Å–Ω—ã–π'",
            "–≥": "–∏—â–µ–º '–≥–¥–µ', '–≥–∞—Ä–∞–Ω—Ç–∏–π–Ω—ã–π'",
            "–Ω": "–∏—â–µ–º '–Ω–µ–¥–æ—Ä–æ–≥–æ–π'",
            "—Ü": "–∏—â–µ–º '—Ü–µ–Ω—Ç—Ä'",
            "–º": "–∏—â–µ–º '–º–∞—Å—Ç–µ—Ä', '–º–∞—Å—Ç–µ—Ä—Å–∫–∞—è'",
        }
        
        csg_discovered_words = set()
        csg_total_queries = 0
        
        for anchor in test_anchors:
            print(f"\n--- –Ø–∫–æ—Ä—å: '{anchor}' ---")
            
            for letter, description in target_letters.items():
                # CSG –≤—Ç–æ—Ä–∏—á–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
                csg_query = f"{anchor} {seed} {letter}"
                csg_suggestions = await self.fetch_suggestions(csg_query, country, language)
                csg_total_queries += 1
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: –µ—Å—Ç—å –ª–∏ –≤—Å—Ç–∞–≤–∫–∞ –ú–ï–ñ–î–£ —è–∫–æ—Ä–µ–º –∏ seed?
                inserted_words = []
                
                for suggestion in csg_suggestions:
                    # –£–¥–∞–ª—è–µ–º —è–∫–æ—Ä—å –∏–∑ –Ω–∞—á–∞–ª–∞
                    if suggestion.lower().startswith(anchor.lower()):
                        after_anchor = suggestion[len(anchor):].strip()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ seed –≤ –æ—Å—Ç–∞—Ç–∫–µ
                        if seed.lower() in after_anchor.lower():
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á—Ç–æ –ü–ï–†–ï–î seed
                            seed_position = after_anchor.lower().find(seed.lower())
                            if seed_position > 0:
                                # –ï—Å—Ç—å —Å–ª–æ–≤–∞ –º–µ–∂–¥—É —è–∫–æ—Ä–µ–º –∏ seed!
                                before_seed = after_anchor[:seed_position].strip()
                                if before_seed:
                                    inserted_words.append(before_seed)
                                    csg_discovered_words.add(before_seed)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                status = "‚úÖ –í–°–¢–ê–í–ö–ê!" if len(inserted_words) > 0 else "‚ùå –Ω–µ—Ç –≤—Å—Ç–∞–≤–∫–∏"
                print(f"  '{csg_query}' ({description})")
                print(f"    –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(csg_suggestions)} | {status}")
                
                if len(inserted_words) > 0:
                    print(f"    –ù–ê–ô–î–ï–ù–´ –í–°–¢–ê–í–ö–ò:")
                    for word in set(inserted_words):
                        print(f"      üéØ '{word}'")
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä
                        for s in csg_suggestions:
                            if word in s:
                                print(f"         –ü—Ä–∏–º–µ—Ä: {s}")
                                break
                
                delay = random.uniform(0.5, 1.5)
                await asyncio.sleep(delay)
        
        print(f"\n{'='*60}")
        print(f"‚úÖ –≠–¢–ê–ü 2 –∑–∞–≤–µ—Ä—à—ë–Ω")
        print(f"{'='*60}")
        print(f"–ó–∞–ø—Ä–æ—Å–æ–≤ —Å–¥–µ–ª–∞–Ω–æ: {csg_total_queries}")
        print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö PREFIX —Å–ª–æ–≤: {len(csg_discovered_words)}")
        
        if len(csg_discovered_words) > 0:
            print(f"\nüéâ CSG –†–ê–ë–û–¢–ê–ï–¢! –ù–∞–π–¥–µ–Ω—ã PREFIX —Å–ª–æ–≤–∞:")
            for word in sorted(csg_discovered_words):
                print(f"  ‚Ä¢ {word}")
            
            # ========================================
            # –≠–¢–ê–ü 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö PREFIX
            # ========================================
            print(f"\n{'='*60}")
            print(f"–≠–¢–ê–ü 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö PREFIX")
            print(f"{'='*60}\n")
            
            csg_prefix_keywords = set()
            
            for word in sorted(csg_discovered_words):
                prefix_query = f"{word} {seed}"
                prefix_suggestions = await self.fetch_suggestions(prefix_query, country, language)
                csg_total_queries += 1
                
                if len(prefix_suggestions) > 0:
                    csg_prefix_keywords.update(prefix_suggestions)
                    all_keywords.update(prefix_suggestions)
                    
                    print(f"‚úÖ '{prefix_query}' ‚Üí {len(prefix_suggestions)} PREFIX –Ω–∞–π–¥–µ–Ω–æ!")
                    for s in prefix_suggestions[:3]:
                        print(f"    ‚Ä¢ {s}")
                else:
                    print(f"‚ùå '{prefix_query}' ‚Üí –Ω–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                
                delay = random.uniform(0.5, 1.5)
                await asyncio.sleep(delay)
            
            print(f"\n{'='*60}")
            print(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê CSG")
            print(f"{'='*60}")
            print(f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {csg_total_queries}")
            print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ PREFIX —Å–ª–æ–≤: {len(csg_discovered_words)}")
            print(f"–ù–∞–π–¥–µ–Ω–æ PREFIX –∫–ª—é—á–µ–π: {len(csg_prefix_keywords)}")
            print(f"")
            
            if "—Å–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä" in csg_discovered_words or "—Å–µ—Ä–≤–∏—Å" in csg_discovered_words:
                print(f"üéØ –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê! –ù–∞—à–ª–∏ '—Å–µ—Ä–≤–∏—Å' –∏–ª–∏ '—Å–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä'!")
            else:
                print(f"‚ùå –¶–µ–ª—å –ù–ï –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞: '—Å–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä' –Ω–µ –Ω–∞–π–¥–µ–Ω")
            
        else:
            print(f"\n‚ùå CSG –ù–ï –†–ê–ë–û–¢–ê–ï–¢!")
            print(f"Google –ù–ï –¥–µ–ª–∞–µ—Ç –≤—Å—Ç–∞–≤–∫–∏ –º–µ–∂–¥—É —è–∫–æ—Ä–µ–º –∏ seed")
            print(f"–ú–µ—Ç–æ–¥ –æ—Ç ChatGPT –Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º –∫ Autocomplete API")
        
        print(f"\n{'='*60}")
        print(f"üéâ CSG –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù")
        print(f"{'='*60}")
        print(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(all_keywords)}")
        
        latin_results = 0
        cyrillic_results = 0
        
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫ –æ–±—â–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
            all_keywords.update(wildcard_suggestions)
            wildcard_all_keywords.update(wildcard_suggestions)
            wildcard_total_results += len(wildcard_suggestions)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª–∏–Ω—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            short_results = [s for s in wildcard_suggestions if len(s.split()) <= 3]  # seed + 1 —Å–ª–æ–≤–æ
            long_results = [s for s in wildcard_suggestions if len(s.split()) > 3]    # seed + 2+ —Å–ª–æ–≤–∞
            
            delay = random.uniform(0.5, 2.0)
            
            print(f"[{i+1}/{len(wildcard_symbols)}] '{wildcard_query}'")
            print(f"    {description}")
            print(f"    –í—Å–µ–≥–æ: {len(wildcard_suggestions)} | –ö–æ—Ä–æ—Ç–∫–∏—Ö: {len(short_results)} | –î–ª–∏–Ω–Ω—ã—Ö: {len(long_results)}")
            
            if len(wildcard_suggestions) > 0:
                print(f"    –ü—Ä–∏–º–µ—Ä—ã –∫–æ—Ä–æ—Ç–∫–∏—Ö:")
                for exp in short_results[:3]:
                    print(f"      ‚Ä¢ {exp}")
                
                if len(long_results) > 0:
                    print(f"    –ü—Ä–∏–º–µ—Ä—ã –¥–ª–∏–Ω–Ω—ã—Ö:")
                    for exp in long_results[:3]:
                        print(f"      ‚Ä¢ {exp}")
            else:
                print(f"    ‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            print(f"    –ó–∞–¥–µ—Ä–∂–∫–∞: {delay:.1f}s")
            print()
            await asyncio.sleep(delay)
        
        # –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        all_short = [s for s in wildcard_all_keywords if len(s.split()) <= 3]
        all_long = [s for s in wildcard_all_keywords if len(s.split()) > 3]
        
        print(f"{'='*60}")
        print(f"‚úÖ WILDCARD SUFFIX –∫–æ–º–±–æ-—Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"{'='*60}")
        print(f"–í—Å–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {wildcard_total_results}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π: {len(wildcard_all_keywords)}")
        print(f"  - –ö–æ—Ä–æ—Ç–∫–∏—Ö (seed + 1 —Å–ª–æ–≤–æ): {len(all_short)}")
        print(f"  - –î–ª–∏–Ω–Ω—ã—Ö (seed + 2+ —Å–ª–æ–≤–∞): {len(all_long)}")
        print(f"")
        print(f"üìä –°–†–ê–í–ù–ï–ù–ò–ï –° –ú–û–î–ò–§–ò–ö–ê–¢–û–†–ê–ú–ò:")
        print(f"  –°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥: 29 –∑–∞–ø—Ä–æ—Å–æ–≤ ‚Üí ~250 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ‚Üí ~30-40 —Å–µ–∫")
        print(f"  –ù–æ–≤—ã–π –º–µ—Ç–æ–¥:  {len(wildcard_symbols)} –∑–∞–ø—Ä–æ—Å–æ–≤ ‚Üí {len(wildcard_all_keywords)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ‚Üí ~{len(wildcard_symbols)*1.5:.0f} —Å–µ–∫")
        print(f"")
        
        if len(wildcard_all_keywords) >= 200:
            efficiency = 29 / len(wildcard_symbols)
            print(f"üéâ WILDCARD –°–£–ü–ï–†-–≠–§–§–ï–ö–¢–ò–í–ï–ù!")
            print(f"‚ö° –£—Å–∫–æ—Ä–µ–Ω–∏–µ: –≤ {efficiency:.1f}x —Ä–∞–∑ –º–µ–Ω—å—à–µ –∑–∞–ø—Ä–æ—Å–æ–≤!")
            print(f"‚úÖ –ü–æ–∫—Ä—ã—Ç–∏–µ: {len(wildcard_all_keywords)} –∫–ª—é—á–µ–π (–æ—Ç–ª–∏—á–Ω–æ!)")
        elif len(wildcard_all_keywords) >= 100:
            print(f"‚úÖ WILDCARD –†–ê–ë–û–¢–ê–ï–¢ –•–û–†–û–®–û!")
            print(f"‚ö° –ú–µ–Ω—å—à–µ –∑–∞–ø—Ä–æ—Å–æ–≤, —Ö–æ—Ä–æ—à–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ")
            print(f"‚ö†Ô∏è –ù–æ –Ω–µ–º–Ω–æ–≥–æ –º–µ–Ω—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã")
        else:
            print(f"‚ö†Ô∏è WILDCARD –î–ê–Å–¢ –ú–ê–õ–û –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
            print(f"‚ùå –õ—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –∞/–±/–≤...")
        
        print(f"")
        print(f"–ü—Ä–∏–º–µ—Ä—ã –î–õ–ò–ù–ù–´–• –∑–∞–ø—Ä–æ—Å–æ–≤:")
        for kw in sorted(all_long, key=lambda x: len(x), reverse=True)[:10]:
            word_count = len(kw.split())
            print(f"  [{word_count} —Å–ª–æ–≤] {kw}")
        
        latin_results = 0
        cyrillic_results = 0
        
        # ========================================
        # ADAPTIVE PREFIX - –û–¢–ö–õ–Æ–ß–ï–ù –î–õ–Ø CSG –¢–ï–°–¢–ê
        # ========================================
        print(f"\n‚ö†Ô∏è ADAPTIVE PREFIX –û–¢–ö–õ–Æ–ß–ï–ù –î–õ–Ø CSG –¢–ï–°–¢–ê")
        
        # ========================================
        # INFIX - –û–¢–ö–õ–Æ–ß–ï–ù –î–õ–Ø CSG –¢–ï–°–¢–ê
        # ========================================
        print(f"\n‚ö†Ô∏è INFIX –û–¢–ö–õ–Æ–ß–ï–ù –î–õ–Ø CSG –¢–ï–°–¢–ê")
        infix_results = 0
        
        # ========================================
        # PREFIX - –û–¢–ö–õ–Æ–ß–ï–ù –î–õ–Ø CSG –¢–ï–°–¢–ê
        # ========================================
        print(f"\n‚ö†Ô∏è PREFIX –û–¢–ö–õ–Æ–ß–ï–ù –î–õ–Ø CSG –¢–ï–°–¢–ê")
        prefix_results = 0
        
            
            delay = random.uniform(0.5, 2.0)
            if i < 3 or len(suggestions) > 0:
                print(f"[{i+1}/{len(cyrillic_modifiers)}] '{query}' ‚Üí {len(suggestions)} results (wait {delay:.1f}s)")
            await asyncio.sleep(delay)
        
        print(f"\n‚úÖ –≠–¢–ê–ü 1 –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"–ù–∞–π–¥–µ–Ω–æ SUFFIX —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {stage1_count}")
        print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö PREFIX —Å–ª–æ–≤: {len(potential_prefix_words)}")
        print(f"\n–ü—Ä–∏–º–µ—Ä—ã –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö —Å–ª–æ–≤:")
        for word in sorted(potential_prefix_words)[:15]:
            print(f"  ‚Ä¢ {word}")
        if len(potential_prefix_words) > 15:
            print(f"  ... –∏ –µ—â—ë {len(potential_prefix_words) - 15}")
        
        # ========================================
        # –≠–¢–ê–ü 2: PREFIX –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö —Å–ª–æ–≤
        # ========================================
        print(f"\n{'='*60}")
        print(f"–≠–¢–ê–ü 2: PREFIX –ø—Ä–æ–≤–µ—Ä–∫–∞ (–æ–±—Ä–∞—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã)")
        print(f"{'='*60}")
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º: '[—Å–ª–æ–≤–æ] {seed}'")
        print(f"–°–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {len(potential_prefix_words)}\n")
        
        stage2_keywords = set()
        stage2_count = 0
        successful_prefix = []
        
        for i, word in enumerate(sorted(potential_prefix_words)):
            # –î–µ–ª–∞–µ–º PREFIX –∑–∞–ø—Ä–æ—Å
            prefix_query = f"{word} {seed}"
            prefix_suggestions = await self.fetch_suggestions(prefix_query, country, language)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –†–ï–ê–õ–¨–ù–û–ï —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ (–Ω–µ –ø—Ä–æ—Å—Ç–æ word + seed)
            real_prefix = []
            for suggestion in prefix_suggestions:
                # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –Ω–∞—à–µ–≥–æ —Å–ª–æ–≤–∞ –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç seed - —ç—Ç–æ PREFIX!
                if suggestion.lower().startswith(word) and seed.lower() in suggestion.lower():
                    real_prefix.append(suggestion)
            
            if len(real_prefix) > 0:
                stage2_keywords.update(real_prefix)
                stage2_count += len(real_prefix)
                successful_prefix.append(word)
                all_keywords.update(real_prefix)
                
                print(f"[{i+1}/{len(potential_prefix_words)}] '{prefix_query}' ‚Üí ‚úÖ {len(real_prefix)} PREFIX –Ω–∞–π–¥–µ–Ω–æ!")
                for exp in real_prefix[:3]:
                    print(f"    ‚Ä¢ {exp}")
            elif i < 5:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –¥–∞–∂–µ –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                print(f"[{i+1}/{len(potential_prefix_words)}] '{prefix_query}' ‚Üí ‚ùå –Ω–µ—Ç PREFIX")
            
            delay = random.uniform(0.5, 2.0)
            await asyncio.sleep(delay)
        
        print(f"\n‚úÖ –≠–¢–ê–ü 2 –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ —Å–ª–æ–≤: {len(potential_prefix_words)}")
        print(f"–£—Å–ø–µ—à–Ω—ã—Ö PREFIX —Å–ª–æ–≤: {len(successful_prefix)}")
        print(f"–ù–∞–π–¥–µ–Ω–æ PREFIX –∑–∞–ø—Ä–æ—Å–æ–≤: {stage2_count}")
        
        # ========================================
        # –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê
        # ========================================
        print(f"\n{'='*60}")
        print(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ADAPTIVE PREFIX")
        print(f"{'='*60}")
        print(f"")
        print(f"–≠–¢–ê–ü 1 (SUFFIX –ø–∞—Ä—Å–∏–Ω–≥):")
        print(f"  –ó–∞–ø—Ä–æ—Å–æ–≤: {len(cyrillic_modifiers)}")
        print(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {stage1_count}")
        print(f"  –ò–∑–≤–ª–µ—á–µ–Ω–æ —Å–ª–æ–≤: {len(potential_prefix_words)}")
        print(f"")
        print(f"–≠–¢–ê–ü 2 (PREFIX –ø—Ä–æ–≤–µ—Ä–∫–∞):")
        print(f"  –ó–∞–ø—Ä–æ—Å–æ–≤: {len(potential_prefix_words)}")
        print(f"  –£—Å–ø–µ—à–Ω—ã—Ö: {len(successful_prefix)}")
        print(f"  PREFIX –∑–∞–ø—Ä–æ—Å–æ–≤: {stage2_count}")
        print(f"")
        print(f"–í–°–ï–ì–û:")
        print(f"  –ó–∞–ø—Ä–æ—Å–æ–≤: {len(cyrillic_modifiers) + len(potential_prefix_words)}")
        print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π: {len(all_keywords)}")
        print(f"")
        
        if len(successful_prefix) > 0:
            print(f"üéâ ADAPTIVE PREFIX –†–ê–ë–û–¢–ê–ï–¢!")
            print(f"\n–£—Å–ø–µ—à–Ω—ã–µ PREFIX —Å–ª–æ–≤–∞:")
            for word in successful_prefix[:20]:
                print(f"  ‚Ä¢ {word}")
            if len(successful_prefix) > 20:
                print(f"  ... –∏ –µ—â—ë {len(successful_prefix) - 20}")
            
            print(f"\n–ü—Ä–∏–º–µ—Ä—ã PREFIX –∑–∞–ø—Ä–æ—Å–æ–≤:")
            for kw in sorted(stage2_keywords)[:15]:
                print(f"  ‚Ä¢ {kw}")
            if len(stage2_keywords) > 15:
                print(f"  ... –∏ –µ—â—ë {len(stage2_keywords) - 15}")
        else:
            print(f"‚ùå ADAPTIVE PREFIX –Ω–µ –Ω–∞—à—ë–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        print(f"\n‚ö†Ô∏è SUFFIX Cyrillic –û–¢–ö–õ–Æ–ß–ï–ù –î–õ–Ø –¢–ï–°–¢–ê ADAPTIVE")

        cyrillic_results = 0
        
        # ========================================
        # 3. INFIX —Å –ö–ò–†–ò–õ–õ–ò–¶–ï–ô - –ó–ê–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–û –î–õ–Ø –¢–ï–°–¢–ê
        # ========================================
        # if len(cyrillic_modifiers) > 0 and len(seed_words) >= 2:
        #     print(f"\n{'='*60}")
        #     print(f"üî§ [3/4] INFIX Cyrillic (–∏—Å—Ö–æ–¥–Ω—ã–π seed —Ç–æ–ª—å–∫–æ)")
        #     print(f"{'='*60}")
        #     print(f"–ò—Å—Ö–æ–¥–Ω—ã–π seed: '{seed}'")
        #     print(f"–°–ª–æ–≤ –≤ seed: {len(seed_words)}")
        #     print(f"–®–∞–±–ª–æ–Ω: '{seed_words[0]} [–º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä] {' '.join(seed_words[1:])}'")
        #     print(f"–ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞: '{seed_words[0]} –∞ {' '.join(seed_words[1:])}'")
        #     print(f"–ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤: {len(cyrillic_modifiers)}")
        #     
        #     infix_results = 0
        #     for i, modifier in enumerate(cyrillic_modifiers):
        #         infix_query = f"{seed_words[0]} {modifier} {' '.join(seed_words[1:])}"
        #         infix_suggestions = await self.fetch_suggestions(infix_query, country, language)
        #         all_keywords.update(infix_suggestions)
        #         infix_results += len(infix_suggestions)
        #         
        #         delay = random.uniform(0.5, 2.0)
        #         if i < 3 or len(infix_suggestions) > 0:
        #             print(f"[{i+1}/{len(cyrillic_modifiers)}] '{infix_query}' ‚Üí {len(infix_suggestions)} results (wait {delay:.1f}s)")
        #         await asyncio.sleep(delay)
        #     
        #     print(f"‚úÖ INFIX –∑–∞–≤–µ—Ä—à–µ–Ω: {infix_results} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        # else:
        #     print(f"\n‚ö†Ô∏è INFIX DISABLED (—Ç—Ä–µ–±—É–µ—Ç—Å—è: –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã + seed –∏–∑ 2+ —Å–ª–æ–≤)")
        
        print(f"\n‚ö†Ô∏è INFIX –û–¢–ö–õ–Æ–ß–ï–ù –î–õ–Ø –¢–ï–°–¢–ê WILDCARD")
        infix_results = 0
        
        # ========================================
        # 4. PREFIX - –ó–ê–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–û –î–õ–Ø –¢–ï–°–¢–ê
        # ========================================
        print(f"\n‚ö†Ô∏è PREFIX (–æ–¥–Ω–æ—Å–∏–º–≤–æ–ª—å–Ω—ã–π) –û–¢–ö–õ–Æ–ß–ï–ù –î–õ–Ø CSG –¢–ï–°–¢–ê")
        prefix_results = 0
        
        # ========================================
        # WILDCARD PREFIX - –û–¢–ö–õ–Æ–ß–ï–ù –î–õ–Ø CSG –¢–ï–°–¢–ê
        # ========================================
        print(f"\n‚ö†Ô∏è WILDCARD PREFIX –û–¢–ö–õ–Æ–ß–ï–ù –î–õ–Ø CSG –¢–ï–°–¢–ê")
        wildcard_total_results = 0
        
            print(f"[{i+1}/{len(wildcard_symbols)}] '{wildcard_query}' ({description})")
            print(f"    –í—Å–µ–≥–æ: {len(wildcard_suggestions)} | –†–∞—Å—à–∏—Ä–µ–Ω–∏–π: {len(real_expansions)} | {status}")
            
            if len(real_expansions) > 0:
                print(f"    –ü—Ä–∏–º–µ—Ä—ã —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π:")
                for exp in real_expansions[:5]:
                    print(f"      ‚Ä¢ {exp}")
            
            print(f"    –ó–∞–¥–µ—Ä–∂–∫–∞: {delay:.1f}s\n")
            await asyncio.sleep(delay)
        
        print(f"{'='*60}")
        print(f"‚úÖ WILDCARD PREFIX —Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"{'='*60}")
        print(f"–í—Å–µ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ: {wildcard_total_results}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(wildcard_total_keywords)}")
        
        if wildcard_total_results > 0:
            print(f"\nüéâ WILDCARD –†–ê–ë–û–¢–ê–ï–¢! –ù–∞–π–¥–µ–Ω–æ {wildcard_total_results} PREFIX –∑–∞–ø—Ä–æ—Å–æ–≤!")
            print(f"\n–í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ PREFIX –∑–∞–ø—Ä–æ—Å—ã:")
            for kw in sorted(wildcard_total_keywords)[:20]:
                print(f"  ‚Ä¢ {kw}")
            if len(wildcard_total_keywords) > 20:
                print(f"  ... –∏ –µ—â—ë {len(wildcard_total_keywords) - 20}")
        else:
            print(f"\n‚ùå WILDCARD –ù–ï –†–ê–ë–û–¢–ê–ï–¢ –≤ Google Autocomplete API")
        
        print(f"\n{'='*60}")
        print(f"üéâ –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–ï–ù")
        print(f"{'='*60}")
        print(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(all_keywords)}")
        
        return list(all_keywords)


# ============================================
# MODELS
# ============================================

class LocationRequest(BaseModel):
    country_code: str

class LocationResponse(BaseModel):
    id: str
    name: str
    type: str

class ParseRequest(BaseModel):
    seed: str
    country: str = "IE"
    language: str = "en"
    use_numbers: bool = False
    use_morphology: bool = False

class ParseResponse(BaseModel):
    seed: str
    keywords: List[str]
    count: int
    requests_made: int
    parsing_time: float


# ============================================
# ENDPOINTS
# ============================================

@app.get("/")
async def root():
    credentials_loaded = all([
        os.getenv('GOOGLE_ADS_DEVELOPER_TOKEN'),
        os.getenv('GOOGLE_ADS_CLIENT_ID'),
        os.getenv('GOOGLE_ADS_CLIENT_SECRET'),
        os.getenv('GOOGLE_ADS_CUSTOMER_ID')
    ])
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏
    morph_status = {
        "russian": {
            "available": PYMORPHY_AVAILABLE,
            "library": "pymorphy2",
            "features": "–≤—Å–µ –ø–∞–¥–µ–∂–∏ –∏ —á–∏—Å–ª–∞" if PYMORPHY_AVAILABLE else "–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ"
        },
        "english": {
            "available": INFLECT_AVAILABLE,
            "library": "inflect",
            "features": "singular/plural" if INFLECT_AVAILABLE else "–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ"
        }
    }
    
    return {
        "service": "Semantic Agent API",
        "version": "3.0.0 (SUFFIX + INFIX + MORPHOLOGY)",
        "status": "running",
        "credentials_loaded": credentials_loaded,
        "morphology": {
            "status": "enabled" if (PYMORPHY_AVAILABLE or INFLECT_AVAILABLE) else "disabled",
            "languages": morph_status
        },
        "parsing_modes": {
            "suffix": "seed + modifier (all modifiers)",
            "infix": "word1 + modifier + word2 (cyrillic only, 1-char)",
            "morphology": "all word forms (pymorphy2 for RU, inflect for EN)"
        },
        "endpoints": {
            "health": "/health",
            "locations": "/api/locations/{country_code}",
            "countries": "/api/countries",
            "test_parser_single": "/api/test-parser/single?query={query}&country={country}&language={language}",
            "test_parser_quick": "/api/test-parser/quick?query={query}&country={country}&language={language}",
            "test_parser_full": "/api/test-parser/full?seed={seed}&country={country}&language={language}&use_numbers={bool}&use_morphology={bool}"
        }
    }

@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "credentials": "loaded" if os.getenv("GOOGLE_ADS_DEVELOPER_TOKEN") else "missing",
        "parser": "enabled (SUFFIX + INFIX + MORPHOLOGY)",
        "morphology": {
            "russian": "enabled ‚úÖ" if PYMORPHY_AVAILABLE else "disabled ‚ùå",
            "english": "enabled ‚úÖ" if INFLECT_AVAILABLE else "disabled ‚ùå"
        }
    }

@app.get("/debug")
async def debug():
    """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ö"""
    debug_info = {
        "pymorphy3": {
            "imported": PYMORPHY_AVAILABLE,
            "error": None
        },
        "inflect": {
            "imported": INFLECT_AVAILABLE,
            "error": None
        }
    }
    
    # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–µ—Ä—Å–∏–∏
    try:
        import pymorphy3
        debug_info["pymorphy3"]["version"] = pymorphy3.__version__ if hasattr(pymorphy3, '__version__') else "unknown"
        debug_info["pymorphy3"]["module_path"] = str(pymorphy3.__file__)
    except Exception as e:
        debug_info["pymorphy3"]["error"] = str(e)
    
    try:
        import inflect
        debug_info["inflect"]["version"] = inflect.__version__ if hasattr(inflect, '__version__') else "unknown"
        debug_info["inflect"]["module_path"] = str(inflect.__file__)
    except Exception as e:
        debug_info["inflect"]["error"] = str(e)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º pkg_resources
    try:
        import pkg_resources
        debug_info["pkg_resources"] = {
            "available": True,
            "version": pkg_resources.__version__ if hasattr(pkg_resources, '__version__') else "unknown"
        }
    except Exception as e:
        debug_info["pkg_resources"] = {
            "available": False,
            "error": str(e)
        }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º setuptools
    try:
        import setuptools
        debug_info["setuptools"] = {
            "available": True,
            "version": setuptools.__version__ if hasattr(setuptools, '__version__') else "unknown"
        }
    except Exception as e:
        debug_info["setuptools"] = {
            "available": False,
            "error": str(e)
        }
    
    return debug_info

@app.get("/api/countries")
async def get_countries():
    countries = [
        {"code": "IE", "name": "Ireland", "flag": "üáÆüá™"},
        {"code": "UA", "name": "–£–∫—Ä–∞—ó–Ω–∞", "flag": "üá∫üá¶"},
        {"code": "US", "name": "United States", "flag": "üá∫üá∏"},
        {"code": "GB", "name": "United Kingdom", "flag": "üá¨üáß"},
        {"code": "DE", "name": "Deutschland", "flag": "üá©üá™"},
        {"code": "FR", "name": "France", "flag": "üá´üá∑"},
        {"code": "ES", "name": "Espa√±a", "flag": "üá™üá∏"},
        {"code": "IT", "name": "Italia", "flag": "üáÆüáπ"},
        {"code": "PL", "name": "Polska", "flag": "üáµüá±"},
        {"code": "RU", "name": "–†–æ—Å—Å–∏—è", "flag": "üá∑üá∫"},
    ]
    return {"countries": countries}

@app.get("/api/locations/{country_code}")
async def get_locations(country_code: str):
    """Get locations from Google Ads API"""
    try:
        # Create config from env vars
        create_google_ads_config()
        
        # Import Google Ads service
        from google_ads_service import get_locations_for_country
        
        locations = get_locations_for_country(country_code)
        return {
            "country_code": country_code,
            "locations": locations,
            "source": "google_ads_api"
        }
    except Exception as e:
        # Fallback to mock data
        print(f"Error: {e}")
        
        mock_data = {
            "IE": {
                "regions": [
                    {"id": "1007321", "name": "Carlow", "type": "County"},
                    {"id": "1007322", "name": "Cavan", "type": "County"},
                    {"id": "1007323", "name": "Clare", "type": "County"},
                    {"id": "1007324", "name": "Cork", "type": "County"},
                    {"id": "1007325", "name": "Donegal", "type": "County"},
                    {"id": "1007326", "name": "Dublin", "type": "County"},
                ],
                "cities": [
                    {"id": "1007340", "name": "Dublin", "type": "City"},
                    {"id": "1007341", "name": "Cork", "type": "City"},
                    {"id": "1007342", "name": "Galway", "type": "City"},
                ]
            },
            "UA": {
                "regions": [
                    {"id": "21135", "name": "–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞", "type": "Oblast"},
                    {"id": "21136", "name": "–ö–∏—ó–≤—Å—å–∫–∞", "type": "Oblast"},
                    {"id": "21137", "name": "–õ—å–≤—ñ–≤—Å—å–∫–∞", "type": "Oblast"},
                ],
                "cities": [
                    {"id": "1012864", "name": "–î–Ω—ñ–ø—Ä–æ", "type": "City"},
                    {"id": "1011969", "name": "–ö–∏—ó–≤", "type": "City"},
                    {"id": "1009902", "name": "–õ—å–≤—ñ–≤", "type": "City"},
                ]
            }
        }
        
        if country_code.upper() in mock_data:
            return {
                "country_code": country_code.upper(),
                "locations": mock_data[country_code.upper()],
                "source": "mock_fallback",
                "error": str(e)
            }
        else:
            return {
                "country_code": country_code.upper(),
                "locations": {"regions": [], "cities": []},
                "source": "mock_fallback",
                "error": str(e)
            }


# ============================================
# PARSER TEST ENDPOINTS
# ============================================

@app.get("/api/test-parser/single")
async def single_test(
    query: str = Query(..., description="Search query to test"),
    country: str = Query("UA", description="Country code (e.g., UA, US)"),
    language: str = Query("ru", description="Language code (e.g., ru, en)")
):
    """
    –¢–µ—Å—Ç –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ Google Autocomplete
    
    –ü—Ä–∏–º–µ—Ä: 
    GET /api/test-parser/single?query=–∫—É–ø–∏—Ç—å%20–±–µ%20–≤–∏–Ω–æ&country=UA&language=ru
    GET /api/test-parser/single?query=—Ä–µ–º–æ–Ω—Ç%20–∞%20–ø—ã–ª–µ—Å–æ—Å–æ–≤&country=UA&language=ru
    """
    parser = AutocompleteParser()
    
    suggestions = await parser.fetch_suggestions(
        query=query,
        country=country,
        language=language
    )
    
    return {
        "query": query,
        "country": country,
        "language": language,
        "suggestions": suggestions,
        "count": len(suggestions),
        "status": "success" if suggestions else "no_results"
    }


@app.get("/api/test-parser/quick")
async def quick_test(
    query: str = "vacuum repair",
    country: str = "IE",
    language: str = "en"
):
    """
    –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –ø–∞—Ä—Å–µ—Ä–∞ - –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –∫ Google Autocomplete
    
    –ü—Ä–∏–º–µ—Ä: GET /api/test-parser/quick?query=—Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤&country=UA&language=ru
    """
    parser = AutocompleteParser()
    
    suggestions = await parser.fetch_suggestions(
        query=query,
        country=country,
        language=language
    )
    
    return {
        "query": query,
        "country": country,
        "language": language,
        "suggestions": suggestions,
        "count": len(suggestions),
        "status": "success" if suggestions else "no_results"
    }


@app.get("/api/test-parser/full")
async def full_test(
    seed: str = "vacuum repair",
    country: str = "IE",
    language: str = "en",
    use_numbers: bool = True,
    use_morphology: bool = False
):
    """
    –ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏ (SUFFIX + INFIX + MORPH)
    
    SUFFIX: seed + –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–≤—Å–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã a-z + –∞-—è + 0-9)
    INFIX: —Å–ª–æ–≤–æ1 + –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä + —Å–ª–æ–≤–æ2 (—Ç–æ–ª—å–∫–æ –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ –∞-—è)
    MORPH: –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º seed —Ñ—Ä–∞–∑—ã
    
    –ü—Ä–∏–º–µ—Ä: GET /api/test-parser/full?seed=—Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤&country=UA&language=ru&use_numbers=true&use_morphology=true
    """
    parser = AutocompleteParser()
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    all_modifiers = parser.get_modifiers(language)
    if not use_numbers:
        all_modifiers = [m for m in all_modifiers if not m.isdigit()]
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
    language_specific = parser.language_modifiers.get(language.lower(), [])
    cyrillic_modifiers = [m for m in all_modifiers if m in language_specific]
    latin_digit_modifiers = [m for m in all_modifiers if m not in language_specific]
    seed_words = seed.split()
    
    # –ü–æ–ª—É—á–∞–µ–º seed –≤–∞—Ä–∏–∞—Ü–∏–∏ –µ—Å–ª–∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –≤–∫–ª—é—á–µ–Ω–∞
    seed_variations = 1
    morph_available = False
    # –ú–û–†–§–û–õ–û–ì–ò–Ø –ó–ê–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–ê –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø PREFIX  
    # if use_morphology:
    #     if language.lower() == 'ru' and PYMORPHY_AVAILABLE:
    #         morph_available = True
    #     elif language.lower() == 'en' and INFLECT_AVAILABLE:
    #         morph_available = True
    #     
    #     if morph_available:
    #         variations = parser.get_seed_variations(seed, language)
    #         seed_variations = len(variations)
    
    # –ü–†–ê–í–ò–õ–¨–ù–´–ô –†–ê–°–ß–ï–¢ (–ú–û–†–§–û–õ–û–ì–ò–Ø –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ï–ù–ê):
    # 1. SUFFIX –ª–∞—Ç–∏–Ω–∏—Ü–∞/—Ü–∏—Ñ—Ä—ã (–ë–ï–ó –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏)
    suffix_latin_requests = len(latin_digit_modifiers)
    
    # 2. SUFFIX –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ (–ë–ï–ó –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏ - –í–†–ï–ú–ï–ù–ù–û!)
    suffix_cyrillic_requests = len(cyrillic_modifiers) * seed_variations
    
    # 3. INFIX –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ (–ë–ï–ó –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏!)
    infix_requests = len(cyrillic_modifiers) if len(seed_words) >= 2 else 0
    
    # 4. PREFIX –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ (–ë–ï–ó –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏!) - –ù–û–í–û–ï!
    prefix_requests = len(cyrillic_modifiers)
    
    # –í–°–ï–ì–û –∑–∞–ø—Ä–æ—Å–æ–≤
    total_requests = suffix_latin_requests + suffix_cyrillic_requests + infix_requests + prefix_requests

    
    start_time = time.time()
    
    keywords = await parser.parse_with_modifiers(
        seed=seed,
        country=country,
        language=language,
        use_numbers=use_numbers,
        use_morphology=use_morphology
    )
    
    parsing_time = time.time() - start_time
    
    return {
        "seed": seed,
        "country": country,
        "language": language,
        "modifiers_info": {
            "total_modifiers": len(all_modifiers),
            "latin_digit_modifiers": len(latin_digit_modifiers),
            "cyrillic_modifiers": len(cyrillic_modifiers),
            "base": "a-z" + (" + 0-9" if use_numbers else ""),
            "language_specific": "".join(language_specific) or "none"
        },
        "morphology_info": {
            "enabled": use_morphology,
            "available": morph_available,
            "seed_variations": seed_variations if morph_available else 1,
            "library": "pymorphy2" if language.lower() == 'ru' else "inflect" if language.lower() == 'en' else "none"
        },
        "requests_info": {
            "suffix_latin_digit": suffix_latin_requests,
            "suffix_cyrillic": suffix_cyrillic_requests,
            "infix": infix_requests,
            "prefix": prefix_requests,
            "total_requests": total_requests,
            "formula": f"{suffix_latin_requests} (latin/digit) + {suffix_cyrillic_requests} (cyrillic√ó{seed_variations}) + {infix_requests} (infix) + {prefix_requests} (prefix) = {total_requests}"
        },
        "keywords": keywords,
        "count": len(keywords),
        "requests_made": total_requests,
        "parsing_time": round(parsing_time, 2)
    }


@app.post("/api/test-parser", response_model=ParseResponse)
async def test_parser(request: ParseRequest):
    """
    –ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏ (a-z, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ 0-9, –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è)
    
    –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞:
    POST /api/test-parser
    {
        "seed": "—Ä–µ–º–æ–Ω—Ç –ø—ã–ª–µ—Å–æ—Å–æ–≤",
        "country": "UA",
        "language": "ru",
        "use_numbers": false,
        "use_morphology": true
    }
    """
    parser = AutocompleteParser()
    
    start_time = time.time()
    
    keywords = await parser.parse_with_modifiers(
        seed=request.seed,
        country=request.country,
        language=request.language,
        use_numbers=request.use_numbers,
        use_morphology=request.use_morphology
    )
    
    parsing_time = time.time() - start_time
    
    # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
    all_modifiers = parser.get_modifiers(request.language)
    if not request.use_numbers:
        all_modifiers = [m for m in all_modifiers if not m.isdigit()]
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
    language_specific = parser.language_modifiers.get(request.language.lower(), [])
    cyrillic_modifiers = [m for m in all_modifiers if m in language_specific]
    latin_digit_modifiers = [m for m in all_modifiers if m not in language_specific]
    seed_words = request.seed.split()
    
    # –ú–û–†–§–û–õ–û–ì–ò–Ø –ó–ê–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–ê –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø PREFIX
    # Seed –≤–∞—Ä–∏–∞—Ü–∏–∏ –µ—Å–ª–∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –≤–∫–ª—é—á–µ–Ω–∞
    seed_variations = 1
    # if request.use_morphology:
    #     morph_available = (request.language.lower() == 'ru' and PYMORPHY_AVAILABLE) or \
    #                      (request.language.lower() == 'en' and INFLECT_AVAILABLE)
    #     if morph_available:
    #         variations = parser.get_seed_variations(request.seed, request.language)
    #         seed_variations = len(variations)
    
    # –†–∞—Å—á–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (–ú–û–†–§–û–õ–û–ì–ò–Ø –û–¢–ö–õ–Æ–ß–ï–ù–ê, –î–û–ë–ê–í–õ–ï–ù PREFIX)
    suffix_latin = len(latin_digit_modifiers)
    suffix_cyrillic = len(cyrillic_modifiers) * seed_variations
    infix = len(cyrillic_modifiers) if len(seed_words) >= 2 else 0
    prefix = len(cyrillic_modifiers)  # –ù–û–í–û–ï!
    total_requests = suffix_latin + suffix_cyrillic + infix + prefix
    
    return ParseResponse(
        seed=request.seed,
        keywords=keywords,
        count=len(keywords),
        requests_made=total_requests,
        parsing_time=round(parsing_time, 2)
    )


if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
